{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "sklearn.set_config(print_changed_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic Feature Selection\n",
    "## Univariate statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "\n",
    "## Feature Selection\n",
    "\n",
    "\n",
    "\n",
    "Alright, so let's talk about automatic feature selection. I\n",
    "want to talk about what methods are there to determine what\n",
    "features are important for your dataset, what features are\n",
    "important for a particular model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "\n",
    "## Why Select Features?\n",
    "\n",
    "- Avoid overfitting (?)\n",
    "- Faster prediction and training\n",
    "- Less storage for model and dataset\n",
    "- More interpretable model\n",
    "\n",
    "\n",
    "\n",
    "There's a couple of reasons why you might want to feature\n",
    "selection. One is to avoid overfitting and get a better\n",
    "model. In practice, I have rarely seen that happen. It's not\n",
    "usually what I would try to do to increase performance. If\n",
    "I’m only interested in performance I probably would not try\n",
    "to do automatic feature selection unless I think only a very\n",
    "small subset of my feature is actually important. There's a\n",
    "lot of increasing performance just by selecting only\n",
    "important features.\n",
    "\n",
    "What I think is more commonly, the reason to do automatic\n",
    "feature selection is you want to shrink your model to make\n",
    "faster predictions, to train your model faster, to store\n",
    "fewer data and possibly to collect fewer data. If you're\n",
    "collecting the data or to feature from some online process,\n",
    "maybe it means you need fewer features, you need to store\n",
    "less information. I think actually the top reason to do\n",
    "feature selection is to have a more interpretable model. If\n",
    "your model is smaller, if your model has 5 features instead\n",
    "of 500, it's probably much easier for you to grasp what the\n",
    "model does. If you can have a model that is as good with way\n",
    "fewer features, it will be much easier to explain and most\n",
    "people will be happy with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "\n",
    "## Types of Feature Selection\n",
    "\n",
    "- Unsupervised vs Supervised\n",
    "- Univariate vs Multivariate\n",
    "- Model based or not\n",
    "\n",
    "\n",
    "\n",
    "There's a couple of different types of feature selection\n",
    "that I want to talk about. You can have supervised and\n",
    "unsupervised feature selection. Depending on whether you\n",
    "consider the target or not. You can have Univariate versus\n",
    "Multivariate feature selection. Whereas Univariate looks at\n",
    "each feature at a time and determines if it’s important.\n",
    "Multivariate looks at interactions as well. And you can have\n",
    "a feature selection based on a particular machine learning\n",
    "model or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "\n",
    "## Unsupervised Feature Selection\n",
    "\n",
    "- May discard important information\n",
    "- Variance-based: 0 variance or mostly constant\n",
    "- Covariance-based: remove correlated features\n",
    "- PCA: remove linear subspaces\n",
    "\n",
    "\n",
    "\n",
    "So the simpler thing that you might try is to do\n",
    "unsupervised feature selection which means just discard some\n",
    "features based on the statistics. For example, you could\n",
    "remove features that are mostly constant or that have zero\n",
    "variance. Like if they're always constant, then definitely\n",
    "they're not going to help you and you can remove them. If\n",
    "they have very small variance, on the other hand, that might\n",
    "only mean the scale of the features is small and you should\n",
    "just re-scale the feature. So just because it has a small\n",
    "variance, it doesn't really mean anything. People often\n",
    "discard covariance features. But maybe just the difference\n",
    "between these two correlated features was the thing that's\n",
    "important for prediction. If you use any unsupervised\n",
    "method, then you don't know what are the things that are\n",
    "actually important are. Similarly, with PCA, it’s not really\n",
    "feature selection, because it doesn't select subsets of the\n",
    "original feature. PCA will always use all original features.\n",
    "But it will remove linear subspaces of the feature space.\n",
    "And again, a lot of people like this to reduce the\n",
    "dimensionality and you will get the same things like a\n",
    "smaller model, maybe not more interpretable. It might be\n",
    "that the information you discarded is just the information\n",
    "that's important. In a covariance sense, just because the\n",
    "data doesn't extend a lot in a particular direction doesn't\n",
    "mean that this direction isn't the most important one for\n",
    "your prediction problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance\n",
    "\n",
    ".smaller[\n",
    "```python\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "boston = load_boston()\n",
    "X, y = boston.data, boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "X_train_scaled = scale(X_train)\n",
    "\n",
    "cov = np.cov(X_train_scaled, rowvar=False)\n",
    "```\n",
    "]\n",
    ".center[\n",
    "![:scale 32%](images/img_17.png)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "Here's what the covariance matrix looks like for the Boston\n",
    "housing data set. The way you could do covariance based\n",
    "feature selection is you look at the features that have the\n",
    "highest covariance and just drop one of them or you could\n",
    "sum over all the features and look at which features most\n",
    "correlated with the other ones and drop that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from scipy.cluster import hierarchy\n",
    "order = np.array(hierarchy.dendrogram(\n",
    "    hierarchy.ward(cov),no_plot=True)['ivl'], dtype=\"int\")\n",
    "```\n",
    "\n",
    ".center[\n",
    "![:scale 90%](images/img_19.png)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "So if you look at covariance, it should probably try to sort\n",
    "your features using some clustering. Here I'm using\n",
    "hierarchical clustering from scipy. On the right, it’s the\n",
    "covariance matrix and on the left, it's also the covariance\n",
    "matrix where I reordered the columns and rows. You can see\n",
    "that there are three correlated blocks. You could do this\n",
    "automatically, or you could look at it and see what you\n",
    "think how many features are there, and how many of them are\n",
    "correlated. I really urge you, whenever you look at\n",
    "correlation, never look at correlation without resorting the\n",
    "columns. On the right-hand side here, maybe I can see that\n",
    "these two are correlated, but I can't see anything else.\n",
    "Whereas on the left hand I can see much more clearly what\n",
    "the structure of the data is. What it did just was, it did\n",
    "clustering on the rows and columns to resort them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "\n",
    "## Supervised Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Statistics\n",
    "\n",
    ".smaller[\n",
    "- Pick statistic, check p-values !\n",
    "- f_regression, f_classsif, chi2 in scikit-learn\n",
    "```python\n",
    "from sklearn.feature_selection import f_regression\n",
    "f_values, p_values = f_regression(X, y)\n",
    "```\n",
    "]\n",
    ".center[\n",
    "![:scale 60%](images/img_20.png)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "So the simplest way is univariate features selection without\n",
    "models. The most classical one is to use statistical test\n",
    "and see the ones that are significantly related to the\n",
    "target. Depending on whether you look through classification\n",
    "or regression, you can add a t-test, f-test or chi-squared\n",
    "test and you can say which are the features that are\n",
    "significantly related with a target and I'm just going to\n",
    "select these.\n",
    "\n",
    "So this is again here for the Boston housing dataset, using\n",
    "F regression and F test. You can see here F values and the P\n",
    "values and you could use either of them to select a subset\n",
    "of the features. So for example, the number of rooms and\n",
    "LSTAT had very high F values, very small P values. These are\n",
    "certainly the most important features. While this one here\n",
    "doesn't seem very important. One reason why this is not very\n",
    "important is because this is the binary variable and so this\n",
    "assumes linear regression model and the linear regression\n",
    "model is not very good at exploiting the binary variable.\n",
    "\n",
    "This is a super quick test to do. It's very fast, it's\n",
    "probably something you want to look at. But it assumes a\n",
    "linear model, which you might not want to assume."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".smaller[\n",
    "```python\n",
    "from sklearn.feature_selection import SelectKBest, SelectPercentile, SelectFpr\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "select = SelectKBest(k=2, score_func=f_regression)\n",
    "select.fit(X_train, y_train)\n",
    "print(X_train.shape)\n",
    "print(select.transform(X_train).shape)\n",
    "```\n",
    "```\n",
    "(379, 13)\n",
    "(379, 2)\n",
    "```\n",
    "]\n",
    "--\n",
    ".smaller[\n",
    "```python\n",
    "all_features = make_pipeline(StandardScaler(), RidgeCV())\n",
    "np.mean(cross_val_score(all_features, X_train, y_train, cv=10))\n",
    "```\n",
    "0.718\n",
    "]\n",
    "--\n",
    ".smaller[\n",
    "```python\n",
    "select_2 = make_pipeline(StandardScaler(),\n",
    "                         SelectKBest(k=2, score_func=f_regression), RidgeCV())\n",
    "np.mean(cross_val_score(select_2, X_train, y_train, cv=10))\n",
    "```\n",
    "0.624\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "If you want to use these univariate statistics in\n",
    "scikit-learn there’s a couple of tools to select features\n",
    "based on this. In feature selection, there's a whole bunch\n",
    "of them. There select k best which selects the K best\n",
    "feature, you can specify the number of features you want.\n",
    "Select percentile, which selects a percentile that you want\n",
    "and then there's select FPR, it controls for the false\n",
    "positive rate, it basically does the multiple hypothesis\n",
    "testing adjustments to make sure that you false discovery\n",
    "rate of thinking the features are significantly important is\n",
    "low. These are scikit-learn transformers, you can\n",
    "instantiate them. By default, the parameter they all use a\n",
    "score function for classification. So if you want to do\n",
    "regression, you need to set the score function to F\n",
    "regression because you need different tests for regression\n",
    "classification. I said linear regression is not for binary\n",
    "features, maybe I shouldn't have formulated in that way.\n",
    "Linear regression doesn't allow you to do interactions,\n",
    "which is if you have multiple binary features would be the\n",
    "only issue. It's more sort of that this linear test will not\n",
    "put a lot of emphasis on a binary feature because the way\n",
    "the test works. I can obviously also put this in a pipeline.\n",
    "Here, I’ve used a centered scale for ridge in a pipeline for\n",
    "a Boston housing data set and here, I’ve used two best\n",
    "features. You can see it actually got much worse because two\n",
    "features are not enough to select or to express all the\n",
    "information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mututal Information\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "scores = mutual_info_regression(X_train, y_train,\n",
    "                                discrete_features=[3])\n",
    "```\n",
    ".center[\n",
    "![:scale 90%](images/img_22.png)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Another univariate statistics that you can use which is a\n",
    "little bit more complicated, which is called Mutual\n",
    "Information. There's a version for regression classification\n",
    "in scikit-learn. This doesn't use a linear model. It uses a\n",
    "non-parametric model using nearest neighbors. So basically,\n",
    "this also works if the interaction is nonlinear and it works\n",
    "on discrete and continuous features, but you have to tell us\n",
    "which features are discrete. So here, in this case, I tell\n",
    "it the feature number three is discrete and then this gives\n",
    "me some scores telling me what's the mutual information\n",
    "between this feature in the target. Here I'm comparing the F\n",
    "values off the standard regression tests with the mutual\n",
    "information and they are sort of similar, but not entirely.\n",
    "If you think there are nonlinear interactions, and you have\n",
    "a model that can capture nonlinear interactions, then doing\n",
    "feature selection like taking these nonlinear features into\n",
    "account is good. This is much more computationally intensive\n",
    "than doing the F statistics. But this is still Univariate,\n",
    "looking at one feature at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "\n",
    "#Model-Based Feature Selection\n",
    "\n",
    "- Get best fit for a particular model\n",
    "- Ideally: exhaustive search over all possible\n",
    "combinations\n",
    "- Exhaustive is infeasible (and has multiple testing\n",
    "issues)\n",
    "- Use heuristics in practice.\n",
    "\n",
    "\n",
    "\n",
    "So now let's look at multiple features at a time. Most of\n",
    "the things that look at multiple features at a time are\n",
    "model-based. Usually, model-based feature selection finds\n",
    "the subset of features on which this model performs best. So\n",
    "giving them a particular model like a linear model, or\n",
    "random forest, I want to find a subset of features for which\n",
    "this model performs best in terms of cross-validation\n",
    "performance. Ideally, to do that, I would do an exhaustive\n",
    "search over all possible subsets of the features. But that's\n",
    "like exponentially many. Also, if I do so many models fits I\n",
    "might overfit. So instead, there are several heuristics you\n",
    "can use to basically shrink or grow the sets of features\n",
    "that you're using.\n",
    "\n",
    "So first you fix the model. For models that give you some\n",
    "measure of feature importance, there's a very simple\n",
    "technique which just looks at how important the models\n",
    "feature is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model based (single fit)\n",
    ".smaller[\n",
    "- Build a model, select \"features important to model\"\n",
    "- Lasso, other linear models, tree-based Models\n",
    "- Multivariate - linear models assume linear relation\n",
    "]\n",
    ".smaller[\n",
    "```python\n",
    "from sklearn.linear_model import LassoCV\n",
    "X_train_scaled = scale(X_train)\n",
    "lasso = LassoCV().fit(X_train_scaled, y_train)\n",
    "print(lasso.coef_)\n",
    "```\n",
    "[-0.881  0.951 -0.082  0.59  -1.69   2.639 -0.146 -2.796  1.695 -1.614\n",
    " -2.133  0.729 -3.615]\n",
    "]\n",
    "\n",
    ".center[\n",
    "![:scale 55%](images/img_23.png)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "Using, say, a linear model, you fit the single model, and\n",
    "you discard all the features that the model doesn't think\n",
    "are important. So this works for linear models really well\n",
    "and for tree-based models. This allows you to take linear\n",
    "interactions into account and with trees it allows you to\n",
    "take arbitrary interactions into account. So for example, I\n",
    "can use lasso, I can fit the lasso on my model, and I can\n",
    "look at the coefficients and the things that have small\n",
    "coefficients are less important in some sense, and so I\n",
    "could discard some of them. Here again, I plot the F values\n",
    "versus the coefficients of lasso. For example, here you can\n",
    "see for this variable, Lasso thinks its way less important\n",
    "than Univariate selection. Maybe because it was explained\n",
    "already by a combination of the other features. So if you\n",
    "have very co-related features Univariate selection will give\n",
    "all of them the same importance whereas lasso will usually\n",
    "pick only one of them. If you have many co-related features\n",
    "lasso picks only one of them at random. So it doesn't mean\n",
    "that other features are not important. Question is what does\n",
    "this purple don't represent? It represents that both the\n",
    "points are overlapping entirely.\n",
    "\n",
    "Here I use lassoCV which means it adjusted the\n",
    "regularization parameter in Lasso to make the optimum\n",
    "predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing Lasso alpha\n",
    "\n",
    ".smaller[\n",
    "```python\n",
    "from sklearn.linear_model import Lasso\n",
    "X_train_scaled = scale(X_train)\n",
    "lasso = Lasso().fit(X_train_scaled, y_train)\n",
    "print(lasso.coef_)\n",
    "```\n",
    "[-0.     0.    -0.     0.    -0.     2.529 -0.    -0.    -0.    -0.228\n",
    " -1.701  0.132 -3.606]\n",
    "]\n",
    "\n",
    ".center[\n",
    "![:scale 80%](images/img_24.png)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "If I look at the different alpha, it might be quite\n",
    "different. For example here with a default alpha of one, a\n",
    "lot of the coefficients are exactly zero and you can see it\n",
    "would only select five. How to select the alpha in lasso is\n",
    "important for the feature selection and so you might want to\n",
    "grid search. Now, let’s say we want to use this and so we\n",
    "want a scikit-learn estimator that does this. So we can put\n",
    "it in a pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "## SelectFromModel\n",
    "\n",
    "```python\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "select_lassocv = SelectFromModel(LassoCV(), threshold=1e-5)\n",
    "select_lassocv.fit(X_train, y_train)\n",
    "print(select_lassocv.transform(X_train).shape)\n",
    "```\n",
    "```\n",
    "(379,11)\n",
    "```\n",
    "--\n",
    "```python\n",
    "pipe_lassocv = make_pipeline(StandardScaler(), select_lassocv, RidgeCV())\n",
    "np.mean(cross_val_score(pipe_lassocv, X_train, y_train, cv=10))\n",
    "np.mean(cross_val_score(all_features, X_train, y_train, cv=10))\n",
    "```\n",
    "```\n",
    "0.717\n",
    "0.718\n",
    "```\n",
    "--\n",
    "```python\n",
    "## could grid-search alpha in lasso\n",
    "select_lasso = SelectFromModel(Lasso())\n",
    "pipe_lasso = make_pipeline(StandardScaler(), select_lasso, RidgeCV())\n",
    "np.mean(cross_val_score(pipe_lasso, X_train, y_train, cv=10))\n",
    "```\n",
    "```\n",
    "0.671\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "SelectFrom model will work with any model with coef_ or feature_importances_.\n",
    "So that’s any linear model or tree based model. It uses this to\n",
    "select the features. So this will fit lasso and then if you\n",
    "call transform, it will discard all the features that lasso\n",
    "thought are not important. And you can change the threshold\n",
    "here, for example, so in this case, here I want to discard\n",
    "everything that lasso put to zero so I put a very small\n",
    "threshold in there. I could also set the threshold to be the\n",
    "median which selects 50% of the features. Here we are\n",
    "possibly discarding multiple features at once.\n",
    "SelectFromModel fits a single model, gets the feature\n",
    "importance was from this model and then drops according to\n",
    "the feature importance. And so here is how it looks in the\n",
    "pipeline, for example, you can see here that lasso with\n",
    "these parameters, drop two of the features and 11 after 13\n",
    "remains. If I put it in a pipeline the performance is about\n",
    "the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "\n",
    "## Iterative Model-Based Selection\n",
    "\n",
    "- Fit model, find least important feature, remove, iterate.\n",
    "- Or: Start with single feature, find most important feature, add, iterate.\n",
    "\n",
    "\n",
    "\n",
    "But maybe dropping multiple features at once is not a good\n",
    "idea because the importance of the features might change\n",
    "once we dropped some of them. What we can do is, we can\n",
    "iteratively build models. And we could either start with a\n",
    "single feature then add more important ones or we could\n",
    "start with all features and discard some.\n",
    "\n",
    "We'll talk about these two strategies which are slightly\n",
    "different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "\n",
    "## Recursive Feature Elimination\n",
    "\n",
    "- Uses feature importances / coefficients, similar to “SelectFromModel”\n",
    "- Iteratively removes features (one by one or in groups)\n",
    "- Runtime: (n_features - n_feature_to_keep) / stepsize\n",
    "\n",
    "\n",
    "\n",
    "So the next step from what we just saw would be recursive\n",
    "feature elimination. So if we use SelectFromModel it will\n",
    "drop all the unimportant features at once, in a recursive\n",
    "feature elimination usually drops one feature at a time or\n",
    "as a parameter step size it drops step size features at a\n",
    "time. So you fit the model, you discard the least important\n",
    "feature, you fit the model, you discard the important\n",
    "feature and so on until you have as many features left as\n",
    "you want again. Again, this needs the model to meet some\n",
    "measure of feature importance so you can use this with the\n",
    "linear model or tree-based model. An example where you\n",
    "cannot use this is, at least not in scikit-learn is Kernel\n",
    "SVM or neural networks, because they don't really give you a\n",
    "measure of feature importance easily. For each step feature\n",
    "that we remove, we need to train a new model. So this is\n",
    "much more expensive because we need to retrain the model\n",
    "many times, but we're sort of being more careful in how we\n",
    "remove the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".smaller[\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "## create ranking among all features by selecting only one\n",
    "rfe = RFE(LinearRegression(), n_features_to_select=1)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "rfe.ranking_\n",
    "```\n",
    "array([ 9,  8, 13, 11,  5,  2, 12,  4,  7,  6,  3, 10,  1])\n",
    "]\n",
    "\n",
    "\n",
    ".center[\n",
    "![:scale 95%](images/img_27.png)\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This is implemented in RFE, for recursive feature\n",
    "elimination, it works similar to SelectFromModel. To do RFE,\n",
    "then the model that you want to use and then you can specify\n",
    "how many features you want to select. Here I'm comparing the\n",
    "ranking according to RFE. So when it dropped out the\n",
    "features to the linear regression coefficients, which is\n",
    "basically what I would use if I drop them off all at once,\n",
    "and you can see that they're sort of similar. So there's\n",
    "probably not a whole lot of difference, at least in this\n",
    "case. You need to specify how many features you want to\n",
    "select. But if you want to select only one feature, you have\n",
    "to build many models and drop all the other features and so\n",
    "on the way you tried out the model for keeping five features\n",
    "and so on. So if you want a grid search this, doing this\n",
    "independently would be a whole waste of time because they\n",
    "would do the same thing over and over again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV\n",
    ".smaller[\n",
    "```python\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFECV\n",
    "rfe = RFECV(LinearRegression(), cv=10)\n",
    "rfe.fit(X_train_scaled, y_train)\n",
    "print(rfe.support_)\n",
    "print(boston.feature_names[rfe.support_])\n",
    "```\n",
    "```\n",
    "[ True  True False  True  True  True False  True  True  True  True  True\n",
    "  True]\n",
    "['CRIM' 'ZN' 'CHAS' 'NOX' 'RM' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'B' 'LSTAT']\n",
    "```\n",
    "```python\n",
    "pipe_rfe_ridgecv = make_pipeline(StandardScaler(),\n",
    "                                 RFECV(LinearRegression(), cv=10), RidgeCV())\n",
    "np.mean(cross_val_score(pipe_rfe_ridgecv, X_train, y_train, cv=10))\n",
    "```\n",
    "```\n",
    "0.710\n",
    "```\n",
    "]\n",
    "\n",
    "\n",
    "So there's a thing called RFECV that allows you to do\n",
    "efficient grid search for the number of features to keep.\n",
    "This basically has built-in cross-validation, provides the\n",
    "number of features to keep.\n",
    "\n",
    "I’ve done RFECVC with linear regression and set it to do 10\n",
    "fold cross-validation and then it will do the recursive\n",
    "feature elimination inside cross-validation and so it goes\n",
    "down from all features to just having one feature and with\n",
    "cross-validation, it will select the best number."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".smaller[\n",
    "```python\n",
    "pipe_rfe_ridgecv = make_pipeline(StandardScaler(),\n",
    "                                 RFECV(LinearRegression(), cv=10), RidgeCV())\n",
    "np.mean(cross_val_score(pipe_rfe_ridgecv, X_train, y_train, cv=10))\n",
    "```\n",
    "```\n",
    "0.710\n",
    "```\n",
    "```python\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "pipe_rfe_ridgecv = make_pipeline(StandardScaler(), PolynomialFeatures(),\n",
    "                                 RFECV(LinearRegression(), cv=10), RidgeCV())\n",
    "np.mean(cross_val_score(pipe_rfe_ridgecv, X_train, y_train, cv=10))\n",
    "```\n",
    "```\n",
    "0.820\n",
    "```\n",
    "]\n",
    "\n",
    "\n",
    "If we want to predict with the same model as used for\n",
    "selection, RFECV can be used as the prediction step. Could\n",
    "also use RFECV as transformer and use any other model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "\n",
    "## Wrapper Methods\n",
    "\n",
    "- Can be applied for ANY model!\n",
    "- Shrink / grow feature set by greedy search\n",
    "- Called Forward or Backward selection\n",
    "- Run CV / train-val split per feature\n",
    "- Complexity: n_features * (n_features + 1) / 2\n",
    "- Implemented in mlxtend\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "So as I set recourse to each elimination. So this is more\n",
    "careful and it requires the model that gives you feature\n",
    "importance. There's sort of more general reprimand sets that\n",
    "are, in a sense, even more careful, but also more expensive,\n",
    "but it can be applied to any model. These are sequential\n",
    "feature selection. The idea is to either start with zero\n",
    "features, and add the most important feature, or start with\n",
    "all features and remove the least important feature at a\n",
    "time. And you do this by not using a feature importance by\n",
    "the model. But actually each step you basically do like one\n",
    "step looking at search. So let's say I started with all the\n",
    "features, I leave out the first feature, build the model and\n",
    "but I don't only build a model, I do cross-validation of the\n",
    "model on the subset so I get some accuracy or R squared\n",
    "value. And I do this for every single feature. So I leave\n",
    "each feature out and look at the cross-validate accuracy.\n",
    "And I dropped the one that gives me the highest\n",
    "cost-validated accuracy.\n",
    "\n",
    "So now basically, this is even more expensive than doing the\n",
    "recursive feature elimination because I do a one step, look\n",
    "ahead. So now the runtime is quadratic in the number of\n",
    "features. Also for each iteration, I not only need to train\n",
    "a single model, I need to do cross-validation.\n",
    "\n",
    "This is like a pretty standard method, because it's like\n",
    "very general, and you can apply it to any model. It's like a\n",
    "brute force search. Right now it's not in scikit-learn, but\n",
    "it's in a package called mlxtend which has a couple other\n",
    "tools.\n",
    "\n",
    "Mlxtend is luckily fully scikit-learn compatible, so you can\n",
    "put it in a pipeline and everything's fine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SequentialFeatureSelector\n",
    "\n",
    ".smaller[\n",
    "```python\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "sfs = SequentialFeatureSelector(LinearRegression(), forward=False, k_features=7)\n",
    "sfs.fit(X_train_scaled, y_train)\n",
    "```\n",
    "```\n",
    "Features: 7/7\n",
    "```\n",
    "```python\n",
    "print(sfs.k_feature_idx_)\n",
    "print(boston.feature_names[np.array(sfs.k_feature_idx_)])\n",
    "```\n",
    "```\n",
    "(1, 4, 5, 7, 9, 10, 12)\n",
    "['ZN' 'NOX' 'RM' 'DIS' 'TAX' 'PTRATIO' 'LSTAT']\n",
    "```\n",
    "```python\n",
    "sfs.k_score_\n",
    "```\n",
    "```\n",
    "0.725\n",
    "```\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "So from mlxtend, you get feature selection, sequential\n",
    "feature selector, you put into the model, you tell it\n",
    "whether you want to do forward or backward. Forward equal to\n",
    "false means I started with all and I prune features one by\n",
    "one. Forward equal to true means I start with zero features\n",
    "and I use the one that gives me highest accuracy and then I\n",
    "add one by one. As I said with sequential feature selector,\n",
    "you need to specify the number of features and it does\n",
    "internally cross-validation and it optimizes accuracy for\n",
    "classification models and r square for regression models and\n",
    "does this stepwise selection. One thing I should have\n",
    "mentioned if you do feature selection this way,\n",
    "theoretically, you can have a model for feature selection\n",
    "that's different from the model for prediction. In here, if\n",
    "you look at the top for the recursive feature elimination, I\n",
    "use linear regression. But actually, the model I fit in the\n",
    "end was a ridge model. So I could also use, let's say, a\n",
    "tree-based model for feature selection and then the linear\n",
    "model for prediction if I wanted to. It's not entirely clear\n",
    "if that helps or makes sense, but it's sort of an additional\n",
    "degree of freedom. And for example, if I want a very\n",
    "interpretable model, I want my model that does the\n",
    "predictions to be linear so I can explain to my boss what it\n",
    "means. But I can also still do the feature selection using a\n",
    "more complicated model and just tell my boss “Oh, only these\n",
    "features are important and here's how I make the prediction”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    
    "\n",
    "## Questions ?\n",
    "\n",
    "\n",
    "The question is if I do forward method or backward method\n",
    "with the same number of features will the same happen? They\n",
    "both are sort of one step look ahead approximations to\n",
    "trying out all subsets and there's no guarantee we would get\n",
    "the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284, 80)\n",
      "(284, 40)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "# get deterministic random numbers\n",
    "rng = np.random.RandomState(42)\n",
    "noise = rng.normal(size=(len(cancer.data), 50))\n",
    "# add noise features to the data\n",
    "# the first 30 features are from the dataset, the next 50 are noise\n",
    "X_w_noise = np.hstack([cancer.data, noise])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_w_noise, cancer.target, random_state=0, test_size=.5)\n",
    "# use f_classif (the default) and SelectPercentile to select 10% of features:\n",
    "select = SelectPercentile(percentile=50)\n",
    "select.fit(X_train, y_train)\n",
    "# transform training set:\n",
    "X_train_selected = select.transform(X_train)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train_selected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import f_classif, f_regression, chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, p = f_classif(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.semilogy(p, 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = select.get_support()\n",
    "print(mask)\n",
    "# visualize the mask. black is True, white is False\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# transform test data:\n",
    "X_test_selected = select.transform(X_test)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Score with all features: %f\" % lr.score(X_test, y_test))\n",
    "lr.fit(X_train_selected, y_train)\n",
    "print(\"Score with only selected features: %f\" % lr.score(X_test_selected, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-based Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "select = SelectFromModel(RandomForestClassifier(random_state=42),\n",
    "                         threshold=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select.fit(X_train, y_train)\n",
    "X_train_rf = select.transform(X_train)\n",
    "print(X_train.shape)\n",
    "print(X_train_rf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = select.get_support()\n",
    "# visualize the mask. black is True, white is False\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_rf = select.transform(X_test)\n",
    "LogisticRegression().fit(X_train_rf, y_train).score(X_test_rf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "select = RFE(RandomForestClassifier(random_state=42),\n",
    "             n_features_to_select=40)\n",
    "\n",
    "select.fit(X_train, y_train)\n",
    "# visualize the selected features:\n",
    "mask = select.get_support()\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rfe = select.transform(X_train)\n",
    "X_test_rfe = select.transform(X_test)\n",
    "\n",
    "LogisticRegression().fit(X_train_rfe, y_train).score(X_test_rfe, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "sfs = SequentialFeatureSelector(LogisticRegression(), k_features=40, \n",
    "                                forward=False, scoring='accuracy')\n",
    "sfs = sfs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros(80, dtype='bool')\n",
    "mask[np.array(sfs.k_feature_idx_)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression().fit(sfs.transform(X_train), y_train).score(\n",
    "    sfs.transform(X_test), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "Choose either the Boston housing dataset or the adult dataset from above. Compare a linear model with interaction features (with PolynomialFeatures) against one without interaction features.\n",
    "Use feature selection to determine which interaction features were most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/feature_importance.py"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

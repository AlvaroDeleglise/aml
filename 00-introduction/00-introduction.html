

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Introduction &#8212; Applied Machine Learning in Python</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .secondtoggle, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Prerequisits and required libraries" href="01-preliminaries.html" />
    <link rel="prev" title="Welcome" href="../index.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Applied Machine Learning in Python</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../index.html">1. Welcome</a>
  </li>
  <li class="active">
    <a href="">2. Introduction</a>
  <ul class="nav sidenav_l2">
    <li class="">
      <a href="01-preliminaries.html">2.1 Prerequisits and required libraries</a>
    </li>
  </ul>
  </li>
  <li class="">
    <a href="../01-ml-workflow/00-ml-workflow.html">3. The Machine Learning Workflow</a>
  </li>
  <li class="">
    <a href="../02-supervised-learning/index.html">4. Supervised Learning Algorithms</a>
  </li>
  <li class="">
    <a href="../03-unsupervised-learning/index.html">5. Unsupervised Learning Algorithms</a>
  </li>
  <li class="">
    <a href="../04-model-evaluation/index.html">6. Model Evaluation</a>
  </li>
  <li class="">
    <a href="../05-advanced-topics/index.html">7. Advanced Topics</a>
  </li>
</ul>
</nav>
<p class="navbar_footer">Powered by <a href="https://jupyterbook.org">Jupyter Book</a></p>
</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse" data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu" aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation" title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i class="fas fa-download"></i></button>

            
            <div class="dropdown-buttons">
                <!-- ipynb file if we had a myst markdown file -->
                
                <!-- Download raw file -->
                <a class="dropdown-buttons" href="../_sources/00-introduction/00-introduction.ipynb.txt"><button type="button" class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip" data-placement="left">.ipynb</button></a>
                <!-- Download PDF via print -->
                <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF" onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
            </div>
            
        </div>

        <!-- Edit this page -->
        

        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
            <div class="dropdown-buttons">
                
                <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/00-introduction/00-introduction.ipynb"><button type="button" class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip" data-placement="left"><img class="binder-button-logo" src="../_static/images/logo_binder.svg" alt="Interact on binder">Binder</button></a>
                
                
                
            </div>
        </div>
        
    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#scope-and-goals" class="nav-link">Scope and Goals</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#what-is-machine-learning" class="nav-link">What is machine learning?</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#supervised-learning" class="nav-link">Supervised Learning</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h4">
            <a href="#classification-and-regression" class="nav-link">Classification and Regression</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#generalization" class="nav-link">Generalization</a>
        </li>
    
        <li class="nav-item toc-entry toc-h4">
            <a href="#conditions-for-success" class="nav-link">Conditions for success</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#unsupervised-learning" class="nav-link">Unsupervised Learning</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#reinforcement-learning" class="nav-link">Reinforcement Learning</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#isn-t-this-just-statistics" class="nav-link">Isn’t this just statistics?</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#the-bigger-picture" class="nav-link">The bigger picture</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#the-role-of-data" class="nav-link">The role of data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#metrics-and-evaluation" class="nav-link">Metrics and evaluation</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#feedback-loops-in-data-collection" class="nav-link">Feedback loops in data collection</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#when-to-use-and-not-to-use-machine-learning" class="nav-link">When to use and not to use machine learning</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#ethics" class="nav-link">Ethics</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#explainable-ai" class="nav-link">Explainable AI</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#scaling-up" class="nav-link">Scaling up</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#the-machine-learning-process" class="nav-link">The machine learning process</a>
        </li>
    
            </ul>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="introduction">
<h1>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h1>
<p>This book aims to provide an accessible introduction into applying machine learning with Python, in particular using the scikit-learn library.
I assume that you’re already somewhat familiar with Python and the libaries of the scientific Python ecosystem. If you find that you
have a hard time following along some of the details of numpy, matplotlib and pandas, I highly recommend you look at Jake VanderPlas’ <a class="reference external" href="https://jakevdp.github.io/PythonDataScienceHandbook/">Python Data Science handbook</a>.</p>
<div class="section" id="scope-and-goals">
<h2>Scope and Goals<a class="headerlink" href="#scope-and-goals" title="Permalink to this headline">¶</a></h2>
<p>After reading this book, you will be able to do exploratory data analysis on a dataset, evaluate potential machine learning solutions, implement, and evaluate them.
The focus of the book is on tried-and-true methodology for solving real-world machine learning problems. However, we will not go into the details of productionizing and deloying the solutions.
We will mostly focus on what’s know as tabular data, i.e. data that would usually be represented as a pandas DataFrame, Excel Spreadsheet, or CSV file. While we will discuss working with text-data in Chapter, there are many more advanced techniques, for which I’ll point you towards <a class="reference external" href="https://d2l.ai/">Dive into Deep Learning</a> by Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola.
We will not look at image recognition, video or speech data, or time series forecasting, though many of the core concepts described in this book will also apply there.</p>
</div>
<div class="section" id="what-is-machine-learning">
<h2>What is machine learning?<a class="headerlink" href="#what-is-machine-learning" title="Permalink to this headline">¶</a></h2>
<p>Machine learning, also known as predictive modeling in statistics, is a research field and a collection of techniques to extract knowledge from data, often used to automate decision-making processes. Applications of machine learning are pervasive in technology, in particular in complex websites such as facebook, Amazon, youtube or Google. These sites use machine learning to personalize the experience, show relevant content, decide on advertisements, and much more. Without machine learning, none of these services would look anything like they do today.
Outside the web, machine learning has also become integral to commercial applications in manifacturing, logistics, material design, financial markets and many more. Finally, over the last years, machine learning has also become essential to research in practically all data-driven sciences, including physics, astronomy, biology, medicine, earth sciences and social sciences.</p>
<p>There are three main sub-areas of machine learning, supervised learning, unsupervised learning, and reinforcement learning, each of which applies to a somewhat different setting. We’ll discuss each in turn, and give some examples of how they can be used.</p>
<div class="section" id="supervised-learning">
<h3>Supervised Learning<a class="headerlink" href="#supervised-learning" title="Permalink to this headline">¶</a></h3>
<p>Supervised learning is by far the most commonly used in practice. In supervised learning, a model is built from a dataset of input-output pairs, where the input is known as features or independent variables, which we’ll denote by <span class="math notranslate nohighlight">\(x\)</span>, and the output is known as target or label, which we’ll denote by <span class="math notranslate nohighlight">\(y\)</span>. The input here is a representation of an entity of interest, say a customer to your online shop, represented by their age, location and shopping history. The output is a quantity of interest that we want our model to predict, say whether they would buy a particular product if we recommend it to them. To build a model, we need to collect many such pair, i.e. we need to build records of many customers and their decisions about whether or not they bought the product after an recommendation was shown to them. Such a set of input-output pairs for the purpose of building a supervised machine learning model is called a <em>training set</em>.</p>
<div class="margin sidebar">
<p class="sidebar-title">TODO</p>
<p>(customers of bank easier? because discrete products?)</p>
</div>
<p>Once we collected this dataset, we can (attempt to) build a supervised machine learning model that will make a prediction for a new user that wasn’t included in the training dataset. That might enable us to make better recommendations, i.e. only show recommendations to a user that’s likely to buy.</p>
<div class="margin sidebar">
<p class="sidebar-title">TODO</p>
<p>(given an example?)</p>
</div>
<p>The name supervised learning comes from the fact that during learning, the dataset contains the correct targets, which acts as a supervisor for the model training.</p>
<p>For both regression and classification, it’s important to keep in mind the concept of generalization. Let’s say we have a regression task. We have features, that is data vectors x_i and targets y_i drawn from a joint distribution. We now want to learn a function f, such that f(x) is approximately y, not on this training data, but on new data drawn from this distribution. This is what’s called generalization, and this is a core distinction to function approximation. In principle we don’t care about how well we do on x_i, we only care how well we do on new samples from the distribution. We’ll go into much more detail about generalization in about a week, when we dive into supervised learning.</p>
<div class="section" id="classification-and-regression">
<h4>Classification and Regression<a class="headerlink" href="#classification-and-regression" title="Permalink to this headline">¶</a></h4>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p><span class="math notranslate nohighlight">\(^1\)</span> There are many other kinds of supervised learning tasks such as ranking or probability estimation, however, we will focus on classification and regression, the most commonly used tasks, in this book.</p>
</div>
<p>There are two main kinds of supervised learning tasks, called classification and regression<span class="math notranslate nohighlight">\(^1\)</span>. If the target of interest <span class="math notranslate nohighlight">\(y\)</span> that we want to predict is a quantity, the task is a regression problem. If it is discrete, i.e. one of several distinct choices, then it is a classification problem. For example, predicting the time it will take a patient to recover from an illness is a regression task, say measured in days. We might want our model to predict whether a patient will be ready to leave a hospital 3.5 days after admission or 5 or 10. This is regression becaues the time is clearly a continuous quantity, and there is a clear sense of ordering and distance between the different possible predictions. If the correct prediction is that the patient can leave after 4.5 days, but instead we predict 5, that might not be exactly correct, but it might still be a useful prediction. Even 6 might be somewhat useful, while 20 would be totally wrong.</p>
<div class="margin sidebar">
<p class="sidebar-title">TODO?</p>
<p><span class="math notranslate nohighlight">\(^2\)</span> This might be more naturally formulated as a multi-label task, which is basically a series of binary classification tasks. There could be more than one medication that leads to success, so this could be phrased as a yes/no question for each candidate.</p>
</div>
<p>An example for a classification task would be which of a set of medications the patient would respond best to<span class="math notranslate nohighlight">\(^2\)</span>. Here, we have a fixed set of disjoint candidates that are known a-priori, and there is usually no order or sense of distance between the classes. If medication A is the best, then predicting any other medication is a mistake, so we need to predict the exact right outcome for the prediction to be accurate. A very common instance of classification is the special case of binary classification, where there are exactly two choices. Often this can be formulated as a “yes/no” question to which you want to predict an answer. Examples of this are “is this email spam?”, “is there a pedestrian on the street”, “will this customer buy this product” or “should we run an X-ray on this patient”.</p>
<p>The distinction into classification is important, as it will change the algorithms we will use, and the way we measure success. For classification, a common metric is <em>accuracy</em>, the fraction of correctly classified examples, i.e. the fraction of times the model predictied the right class. For regression on the other hand, a common metric is mean squared error, which is the squared average distance from the prediction to the correct answer. In other words, in regression, you want the prediction to be close to the truth, while in classification you want to predict exactly the correct class. In practice, the difference is a bit more subtle, and we will discuss model evaluation in depth in chapter TODO.</p>
<p>Usually it’s quite clear whether a task is classification or regression, but there are some cases that could be solved using either approach. A somewhat common example is ratings in the 5-star rating system that that’s popular on many online platforms. Here, the possible ratings are one start, two starts, three stars, four stars and five stars. So these are discrete choices, and you could apply a classification algorithm. On the other hand, there is a clear ordering, and if the real answer is one star, predicting two stars is probably better than predicting 5 stars, which means it might be more appropriate to use regression. Here, which one is more appropriate depends on the particular algorithm you’re using and how to integrate into your larger workflow.</p>
</div>
<div class="section" id="generalization">
<h4>Generalization<a class="headerlink" href="#generalization" title="Permalink to this headline">¶</a></h4>
<p>When building a model for classification or regression, keep in mind that what we’re interested in is applying the model to new data for which we do not know the outcome. If we build a model for detecting spam emails, but it only works on emails in the training set, i.e. emails the model has seen during building of the model, it will be quite useless. What we want from a spam detection algorithm is to predict reasonably well whether an email is spam or not for a <em>new email</em> that was not included in the training set. The ability for a supervised model to make accurate predictions on new data is called <em>generalization</em> and is the core goal of supervised learning.
Whithout asking for generalization, an algorithm could solve the spam detection task on the training data by just storing all the data, and when presented with one of these emails, look up what the correct answer was. This approach is known as memorization, but it’s impossible to apply to new data.</p>
</div>
<div class="section" id="conditions-for-success">
<h4>Conditions for success<a class="headerlink" href="#conditions-for-success" title="Permalink to this headline">¶</a></h4>
<p>For a supervised learning model to generalize well, i.e. for it to be able to learn to make accurate prediction on new data, some key assumptions must be met:</p>
<p>First, <strong>the necessary information for making the correct prediction actually needs to be encoded in the training data</strong>. For example, if I try to learn to predict a fair coin flip before the coin is tossed, iI won’t be able to build a working machine learning model, no matter what I choose as the input features. The process is very (or entirely?) random, and the information to make a prediction is just not available. More technically, one might say the process has high intrinsic randomness that we can not overcome by building better models. While you’re unlikely to encounter a case as extreme (and obvious) as a coin toss, many processes in the real world are quite random (such as the behavior of people) and it’s impossible to make entirely accurate predictions for them.</p>
<p>In other cases, a prediction might be possible in principle, but we might not have provided the right information to the model. For example, it might be possible for a machine learning model to learn to diagnose pneumonia in a patient, but not if the only information about the patient that we represent to them is their shopping habbits and wardrobe. If we use a chest x-ray as a representation of the patient, together with a collection of symptoms, we will likely have better success.
Even if the information is represented in the input, learning might still fail if the model is unable to extract the information. For example, visual stimuli are very easy to interpret for humans, but in general much harder to understand for machine learning algorithms.
Consequently, it would be much harder for a machine to determine if a graffiti is offensive by presenting it with a photograph, than if the same information was represented as a text file.</p>
<p>Secondly, <strong>the training dataset needs to be large and varied enough to capture the variability of the process</strong>. In other words, the training data needs to be representative of the whole process, not only representing a small portion of it. Humans are very good at abstracting properties, and a child will be able to understand what a car is after seeing only a handfull. Machine learning algorithms on the other hand require a lot of variability to be present. For example, to learn the concept of what a car looks like, an algorithm likely needs to see pictures of vans, of trucks, of sedans, pictures from the front, the side and above, pictures parking and in traffic, pictures in rain and in sunshine, in a garage and outdoors, maybe even pictures taken by a phone camera and pictures taken by a news camera. As we said before, the whole point of supervised learning is to generalize, so we want our model to apply to new settings. However, how new a setting can be depends on the representation of the data and the algorithm in question. If the algorithm has only ever seen trucks, it might not recognize a sedan. If the algorithm has never seen a snow-covered car, it’s unlikely it will recognize it.
Photos (also known as natural images in machine learning) are a very extreme example as they have a lot of variability, and so often require a lot of training data. If your data has a simple structure, or the relationship between your features and your target are simple, then only a handful of training examples might be enough.</p>
<div class="margin sidebar">
<p class="sidebar-title">TODO</p>
<p>example of simple training task</p>
</div>
<p>Third and finally, <strong>the data that the model is applied to needs to be generated from the same process as the data the model was trained on</strong>. A model can only generalize to data that in essence adheres to the same rules and has the same structure.
If I collect data about public transit ridership in Berlin, and use it to make predictions in New York, my model is likely to perform poorly. While I might be able to measure the same things, say number of people at stations, population density, holidays etc, there are so many differences between data collected in Berlin and data collected in New York that it’s unlikely a model trained on one could predict well on the other.
As another example, let’s say you train an image recognition model for recognizing hot dogs on a dataset of stock photos, and you want to deploy it to an app using a phone camera. This is also likely to fail, as stock photography doesn’t resemble photos taken by users pointing their phone. Stock photography is professionally produced and well-lit, the angles are carefully chosen, and often the food is altered to show it in it’s best light (have you noticed how food in a restaurant never looks like in a commercial?). However, machine learning requires you to use a training dataset that was generated by the same process as the data the model will be applied to.</p>
<div class="admonition-mathematical-background alert alert-info">
<p class="admonition-title">Mathematical Background</p>
<p>From a mathematical standpoint, supervised learning assumes that there is a joint distribution <span class="math notranslate nohighlight">\(p(x, y)\)</span> and that the training dataset consists for independent, identically distributed (i.i.d.) samples from this joint distribution.
The model is then applied to new data sampled from the same distribution, but <span class="math notranslate nohighlight">\(y\)</span> is unknown. The model is then used to estimate <span class="math notranslate nohighlight">\(p(y | x)\)</span>, or more commonly the mode of this distribution, i.e. the most likely value for <span class="math notranslate nohighlight">\(y\)</span> to take given the <span class="math notranslate nohighlight">\(x\)</span> we observed.
In the case of learning to predict a coin flip, you could actually learn a very accurate model of <span class="math notranslate nohighlight">\(p(y | x)\)</span>, that predicts heads and tails with equal probability. There is no way to predict the particular outcome itself, though.</p>
<p>The third requirement for success is easily expressed as saying that the test data is sampled i.i.d. from the same distribution <span class="math notranslate nohighlight">\(p(x, y)\)</span> that the training data was generated from.</p>
</div>
<div class="margin sidebar">
<p class="sidebar-title">TODO math</p>
<p>define genearalization here for real? Or do that in chapter 2? decompose classification error into irreducible error estimation error etc…</p>
</div>
</div>
</div>
<div class="section" id="unsupervised-learning">
<h3>Unsupervised Learning<a class="headerlink" href="#unsupervised-learning" title="Permalink to this headline">¶</a></h3>
<p>In unsupervised machine learning, we are usually just given data points <span class="math notranslate nohighlight">\(x\)</span>, and the goal is to learn something about the structure of the data. This is usually a more open-ended task than what we saw in supervised learning. This kind of task is called unsupervised, because even during training, there is no “supervision” providing a correct answer. There are several sub-categories of unsupervised learning that we’ll discuss in Chapter 3, in particular clustering, dimensionality reduction, and signal decomposition.
Clustering is the task of finding coherent groups within a dataset, say subgroups of customers that behave in a similar way, say “students”, “new parents” and “retirees”, that each have a distinct shopping pattern.
However, here, in contrast to classification, the groups are not pre-defined. We might not know what the groups are, how many groups there are, or even if there is a coherent way to define any groups.
There might also be several different ways the data could be grouped: say you’re looking at portraits. One way to group them could be by whether the subject has classes or not. Another way to group them could be by the direction they are facing. Yet another might be hair color or skin color. If you tell an algorithm to cluster the data, you don’t know which aspect it will pick up on, and usually manually inspecting the groups or clusters is the only way to interpret the results.</p>
<p>Two other, related, unsupervised learning tasks are dimensionality reduction and signal decomposition. In these, we are not looking at groups in the data, but underlying factors of variance, that are potentially more semantic than the original representation.
Going back to the example of portraits, an algorithm might find that head orientation, lighting and hair color are important aspects of the image that vary independently. In dimensionality reduction, we are usually looking for a representation that is lower-dimensional, i.e. that has less variables than the original feature space. This can be particularly useful for visualizing dataset with many features, by projecting them into a two-dimensional space that’s easily plotted.
Another common application of signal decomposition is topic modeling of text data. Here, we are trying to find <em>topics</em> among a set of documents, say news articles, or court documents, or social media posts. This is related to clustering, though with the difference that each document can be assigned multiple topics, i.e. topics in the news could be politics, religion, sports and economics, and an article could be about both, politics and economics.</p>
<p>Both, clustering and signal decomposition, are most commonly used in exploratory analysis, where we are trying to understand the data. They are less commonly used in production systems, as they lend themselves less easily to automating a decision process.
Sometimes signal decomposition is used as a mechanism to extract more semantic features from a dataset, on top of which a supervised model is learned. This can be particularly useful if there is a large amount of data, but only a small amount of annotated data, i.e. data for which the outcome <span class="math notranslate nohighlight">\(y\)</span> is known.</p>
</div>
<div class="section" id="reinforcement-learning">
<h3>Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="Permalink to this headline">¶</a></h3>
<p>The third main family of machine learning tasks is reinforcement learning, which is quite different from the other two. Both supervised and unsupervised learning basically work on a dataset that was collected and stored, from which we then build a model. Potentially, this model is then applied to new data in the future.
In reinforcement learning, on the other hand, there is no real notion of a dataset. Instead, reinforcement learning is about a program (usually known as an agent) interacting with a particular environment. Through this interaction, the agent learns to achieve a particular goal. A good example of this is a program learning to play a video game. Here, the agent would be an AI playing the game, while the environment would be the game itself, i.e. the world in which it plays out. The agent is presented with the environment, and has choices of actions (say moving forward and backward and jumping) and each of these actions will result in the environment being in a new state (i.e. with the agent placed a bit forward, or backward, or falling in a hole). Given the new environment, the agent again can choose an action and the environment will be in a new state as a consequence.</p>
<div class="sidebar">
<p class="sidebar-title">render me!</p>
<div class="figure align-default" id="id1">
<a class="reference internal image-reference" href="../_images/reinforcement_cycle.png"><img alt="../_images/reinforcement_cycle.png" src="../_images/reinforcement_cycle.png" style="width: 100%;" /></a>
<p class="caption"><span class="caption-number">Fig. 1 </span><span class="caption-text">The reinforcement learning cycle.</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</div>
</div>
<p>The learning in reinforcement learning happens with so-called <em>rewards</em>, which need to be specified by the data scientist building the system. The agent is trained to seek rewards (hence the name reinforcement learning), and will find series of actions that maximize its reward. In a game, a reward could be given to the environment every time they score points, or just once when the agent wins the game. In the second case, there might be a long delay between the agent taking an action, and the agent winning the game, and one of the main challenges in reinforcement learning is dealing with such settings (this is known as credit attribution problem: which of my actions should I give credit for me winning the game).</p>
<p>Compared with supervised learning, reinforcement learning is a much more indirect way to specify the learning problem: we don’t provide the algorithm with the correct answer (i.e. the correct sequence of actions to win the game), instead we only reward the agent once they achieve a goal. Suprisingly, this can work surprisingly well in practice. This is like learning a game without someone ever telling you the rules, or what the goal of the game is, but only telling you whether you lost or won at the end. As you might expect, it might take you many many tries to figure out the game.</p>
<p>However, algorithms are notoriously patient, and researchers have been able to use reinforcement learning to create programs that can play a wide variety of complex games. Potentially one of the most suprising and impressive feats was learning to play the ancient chinese boardgame of Go at a superhuman level.</p>
<div class="margin sidebar">
<p class="sidebar-title">TODO</p>
<p>citations etc, numbers of games, years…</p>
</div>
<p>When this was publicided in TODO, many researchers in the area were shocked, as the game was known to be notoriously hard, and many believed it could not be learned by any known algorithms. While the initial work used some human knowledge, later publications learned to play the game from scratch, i.e. without any rewards other than for winning the game, by the agent repeatedly playing the game against itself. The resulting programs are now playing at superhuman level, meaning that they are basically unbeatable, even by the best human players in the world. Similar efforts are now underway for other games, in particular computer games like StarCraft II and DOTA.</p>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>Algorithms achieved super-human performance in the game of chess long before this, in the year TODO with the famous play of Kasparov against Deep Blue.
Chess has much fewer possible moves and games are much shorter sequences of actions than in Go or StarCraft, which makes it much easier to devise algorithms to play chess.</p>
</div>
<p>Reinforcement learning also has a long history in other areas, in particular robotics, where it is used for learning and tuning behaviors, such as walking or grasping.
While many impressive achievements have been made with reinforcement learning, there are several aspects that limit it’s broad usefulness.
A potential application of reinforcement learning could be self-driving cars. However, as mentioned above, reinforcement learning usually requires many attempts or iterations before it learns a specific task.
If I wanted to train a car to learn to park, it might fail thousands or hundreds of thousands of times first. Unfortunately, in the real world this is impractical: self-driving cars are very expensive, and we don’t want to crash them over and over again. It might also be risky for the person conducting the experiment. With thousands of attempts, even if the car doesn’t crash, the gas will run out, and the person having to reset the experiment every time will probably get very tired very quickly.
Therefore, reinforcement learning is most successful when there is a good way to simulate the environment, as is the case with games, and with some aspects of robotics.
For learning how to park, a simulation might actually work well, as the sensing of other cars and the steering of the car can be simulated well.
However, for really learning how to drive, a car would need to be able to deal with a variety of situations, such as different weather conditions, crowded streets, people running on the strees, kids chasing balls, navigating detours and many other scenarios.
Simulating these in a realistic way is very hard, and so reinforcement learning is much harder to apply in the physical world.</p>
<p>A setting that has attracted some attention, and might become more relevant soon, is online platforms that are not games. You could think of a social media timeline as an agent that gets rewarded for you looking at it.
Right now, this is often formulated as a supervised learning task (TODO or more acurately active learning). However, your interactions with social media are not usually indepentent events, but your behavior online
is shaped by what is being presented to you, and what was shown to you in the past might influence what is shown to you in the future.
A maybe somewhat cynical analogy would be to think of this as a timeline being an agent, playing you, winning whenever you stay glued to the screen (or click an ad or buy a product).
I’m not aware that this has been implemented anywhere, but as computational capacity increase and algorthms become more sophisticated, it is a natural direction to explore.</p>
<p>Reinforcement learning is a fascinating topic, but much beyond the scope of this book. For an introduction, see TODO Sutten Barto.
For an overview of modern approaches, see TODO.</p>
<p>As you might have notices in the table of contents, this book mostly concerns itself with supervised and unsupervised learning, and we will not discuss reinforcement learning any further.
As a matter of fact, the book heavily emphasizes supervised learning, which has found the larges success among the three in practical applications so far.
While all three of these areas are interesting in their own right, when you see an application of machine learning, or when someone says they are using machine learning for something,
chances are they mean supervised learning, which is arguably the most well-understood, and the most easy to productionize and analyze.</p>
</div>
<div class="section" id="isn-t-this-just-statistics">
<h3>Isn’t this just statistics?<a class="headerlink" href="#isn-t-this-just-statistics" title="Permalink to this headline">¶</a></h3>
<p>A very common question I get is ‘is machine learning not just statistics?’ and I want to quickly address how the approach in this book differs from the approach taken in a statistics class or textbook. The machine learning community and the statistics community have some historical differences (ML being born much later and from within computer science), but study many of the same subjects. So I don’t think it makes sense to say that one thing is statistics and the other thing is machine learning. However, there is usually a somewhat different emphasis in the kinds of problems and questions that are addressed in either, and I think it’s important to distinguish these tasks. Much of statistics often deals with <em>inference</em>, which means that given a dataset, we want to make statements that hold for the dataset (often called population in statistics) as a whole. Machine learning on the other hand often emphasizes <em>prediction</em>, which means we are looking to make statements about each sample, in other words indivdual level statements.
Asking “do people that take zinc get sick less often”” is an inference question, as it asks about whether something happens on average over the whole population. A related prediction question would be “will this particular person get sick if they take zinc?”.
The answer for the inference question would be either “yes” or “no”, and using hypothesis testing methodology this statement could have an effect size and a significance level attached to it. The answer for the prediction question would be a prediction for each sample of interest, or maybe even a program that can make prediction given information about a new patient.</p>
<p>As you can see, these are two fundamentally different kinds of questions, and require fundamentally different kinds of tools to answer them. This book solely looks at the prediction task, and we consider a model a good model if it can make good predictions. We do not claim that the model allows us to make any statistical or even causal statements that hold for the whole population, or the process that generated the dataset.</p>
<p>There are some other interesting differences between the kind of prediction questions studied in supervised machine learning compared to inference questions that are traditionally studied in statistics; in particular, machine learning usually assumes that we have access to data that was generated from the process we want to model, and that all samples are created equal (i.i.d.). Statistical inference usually makes no such assumptions, and instead assumes that we have some knowledge about the structure of the process that generated the data. As an example, consider predicting a presidential election outcome. As of this writing, there’s 58 past elections to learn from. For a machine learning task, this is by no means enough observations to learn from. But even worse, these samples are not created equally. The circumstances of the first election are clearly different than the will be for the next election. The economic and societal situation will be different, as will be the candidates. So really, we have no examples whatsoever from the process that we’re interested in. However, understanding all the differences to previous elections, we might still be able to make accurate forecasts using statistical modeling.</p>
<div class="margin sidebar">
<p class="sidebar-title">TODO</p>
<p>is this math? should this been in a math section?</p>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>If you’re interested in a discussion of prediction vs inference and how they relate, I highly recommend the seminal paper <a class="reference external" href="https://projecteuclid.org/euclid.ss/1009213726">Statistical Modeling: The Two Cultures</a> by Leo Breiman.</p>
</div>
<p>Some of my <a class="reference external" href="https://web.stanford.edu/~hastie/Papers/ESLII.pdf">favorite</a> <a class="reference external" href="http://appliedpredictivemodeling.com/">machine</a> <a class="reference external" href="https://web.stanford.edu/~hastie/CASI/">learning</a> <a class="reference external" href="http://www.feat.engineering/">textbooks</a> are written by statisticians (the subfield is called predictive modeling), and there are certainly machine learning researchers that work on inference questions, so I think making a distinction between statistics and machine learning is not that useful. However, if you look at how a statistics textbook teaches, say, logistic regression, the intention is likely to be inference, and so the methods will be different from this book, where the emphasis is on prediction, and you should keep this in mind.</p>
<p>This is not to say that one is better than the other in any sense, but that it’s important to pick the right tool for the job. If you want to answer an inference question, the tools in this book are unlikely to help you, but if you want to make accurate predictions, they likely will.</p>
</div>
</div>
<div class="section" id="the-bigger-picture">
<h2>The bigger picture<a class="headerlink" href="#the-bigger-picture" title="Permalink to this headline">¶</a></h2>
<div class="section" id="the-role-of-data">
<h3>The role of data<a class="headerlink" href="#the-role-of-data" title="Permalink to this headline">¶</a></h3>
<p>Clearly the data used for building and evaluating a machine learning model are crucial ingredients. How crucial is something that is often overlooked. Much of the education on machine learning looks at fixed datasets, and the same is true for online competitions and platforms such as <a class="reference external" href="https://kaggle.com">kaggle</a>. However, in practice, data collection is usually part of building any machine learning application, and there is usually a choice to collect additional data, or to change the data collection.
Having more data can be the difference between a model that’s not working, and a model that outperforms human judgement, in particular if you can collect data that covers the variablity that you will encounter in prediction.
Sometimes it might be possible to collect additional features that make the task much easier, and selecting what data to collect is often as critical as selecting the right model. Usually it’s easier to throw away data later than to add new fields to the data collection. It’s common for data scientist to start working on a model only to discover that a critical aspect of the process was not logged, and a task that could have been easy becomes extremely hard.</p>
<div class="margin sidebar">
<p class="sidebar-title">TODO</p>
<p>data quality?</p>
</div>
<div class="margin sidebar">
<p class="sidebar-title">ReCAPTCHA</p>
<p>Potentially one of the most ingenious ways to capture labeled training data is <a class="reference external" href="https://en.wikipedia.org/wiki/ReCAPTCHA">ReCAPTCHA</a>. It provides a service to verify that web user is not a bot by solving visual tasks.
These are then used as ground truth annotation for training machine learning models.</p>
</div>
<p>Depending on the problem you’re tackling, the effort and cost of data collection can vary widely. In some settings, the data is basically <em>free and endless</em>. Say you want to predict how much attention a post will receive on social media.
As long as your post is similar to other posts on the platform, you can obtain arbitrary amounts of training data by looking at existing posts, and collect the number of likes and comments and other engagement. This data rich situation often appears when you are tying to predict the future, and you can observe the labels of past data simply by waiting, i.e. seeing how many people like a photo. In some cases the same might be true for showing ads or recommendations, where you are able to observe past behavior of users, or in content moderation, where users might flag offending content for you. This assumes that the feedback loop is relatively small and the events repeat often, though. If you work in retail, the two data points that are most crucial (at least in the US) are Black Friday and Christmas. And while you might be able to observe them, you can only observe them once a year, and if you make a bad decision, you might go out of business before observing them again.</p>
<p>Another common situation is automating a business process that before has been done manually. Usually collecting the answers is not free in this setting, but it’s often possible to collect additional data by <em>manually annotation</em>. The price of collecting more data then depends on the level of qualification required to create accurate labels, and the time involved. If you want to detect personal attacks in your online community, you can likely use a crowd-sourcing platform or a contractor to get reasonable labels. If your decision requires expert knowledge, say, which period a painting was created in, hiring an expert might be much more expensive or even impossible. In this situation, it’s often intersting to ask yourself what is more cost-effective: spending time building and tuning a complex machine learning model, or collecting more data and potentially getting results with less effort. We will discuss how to make this decision in TODO.</p>
<p>Finally, there are situations where getting additional data is infeasible or impossible; in this situations, people speak of <em>precious data</em>. Examples of this could be the outcome of a drug-trial, which is lengthy and expensive and where collecting additional data might not be feasible. Or the simulation of a complex physical system, or observations on a scientific measurement. Maybe each sample corresponds to a new microchip architecture for which you want to model energy efficiency. These settings are those where tweaking your model and diving deep into the problem might pay off, but these situations are overall rather rare in practice.</p>
<div class="margin sidebar">
<p class="sidebar-title">TODO</p>
<p>say why machines are good at some things and bad at others? like medical imaging?</p>
</div>
</div>
<div class="section" id="metrics-and-evaluation">
<h3>Metrics and evaluation<a class="headerlink" href="#metrics-and-evaluation" title="Permalink to this headline">¶</a></h3>
<p>One of the most important parts of machine learning is defining the goal, and defining a way to measure that goal. In this way, Kaggle is a really bad way to prepare you for machine learning in the real world, because they already did that work for you. In the real world, people don’t tell you whether you should use unsupervised learning, supervised learning, classification or regression, and what’s the right way to cast something as a machine learning task – or whether to cast it as machine learning at all.</p>
<p>So think in context of your problem. What do you want to achieve? What is the easiest way to achieve this? And what will improving over this baseline buy you?</p>
<p>The problem of metrics is not unique to machine learning, but a problem in any data driven decision making. And often you have no choice but to use a substitute metric, either because the effect you’re interested in is too hard to measure, or because the influence is too indirect. Imagine spotify improved their artist radio to be waaay better. The metric they care about is revenue. Do you think better radio will increase revenue short-term? What would be a good substitute metric?</p>
<p>Let’s say facebook wants to optimize their ad revenue. What should they measure? If people click on ads, that’s probably good, right? But you can optimize clicks on ads by increasing accidental clicks by putting ads next to things people click. But accidental clicks will not yield conversions, and if you sell clicks to the ad buyers, and they don’t result in conversions, they will go somewhere else.</p>
</div>
<div class="section" id="feedback-loops-in-data-collection">
<h3>Feedback loops in data collection<a class="headerlink" href="#feedback-loops-in-data-collection" title="Permalink to this headline">¶</a></h3>
<p>One aspect that is often neglected in data collection is that the effect of deploying a machine learning model might change the process generating the data.
A simple example for this would be spammers, who, once a model is able to flag their content, would change their strategy or content so as to be no longer detected. Clearly, the data here changed as a consequence of deploying the model, and the model that might have been able to accurately identify spam in an offline setting might not work in practice.
In this example, there is an adverserial intent and the spammers intentionally try to defeat the model. However, similar changes might happen indicentally, but still invalidate a previous model.
For example, when building systems for product recommentation, the model often relies on data that was collected using some other recommendation scheme, and the choice of this scheme clearly influences what data will be collected. If a streaming platform never suggests a particular movie, it’s unlikely to be seen by many users, and so it will not show up in user data that’s collected, and so a machine learning algorithm will not recommend it, creating a feedback loop that will lead to the movie being ignored.
There is a whole subset of machine learning devoted to this kind of interactive data collection, called <em>active learning</em>, where the data that is collected is closely related to the model that’s being build. This area also has a close relation to reinforcement learning.</p>
<p>Given the existence of these feedback loops, it’s important to ensure that your model performs well, not only in an offline test, but also in a production environment. Often this is hard to simulate, as you might not be able to anticipate the reaction of your users to deploying an algorithm. In this case, using A/B testing might be a way to evaluate your system more rigourously.</p>
<div class="margin sidebar">
<p class="sidebar-title">TODO</p>
<p>A/B testing</p>
</div>
<p>A particular nefarious example of this feedback loop has been observed (TODO citation) in what is known as <em>predictive policing</em>. The premise of predictive policing is to send police patrols to neighborhoods where they expect to observe crime, at times that they expect to observe crime. However, if police is sent to a neighborhood, they are likely to find criminal activity there (even if it might be minor); and clearly they will not find criminal activity in neighborhoods they did not patrol. Historically, police patrols in certain US cities have focused on non-white neighborhoods, and given this historical data, predictive policing methods steered patrols to these same neighborhoods. Which then lead them to observe more crime there, leading to more data showing crime in these neighborhoods, leading to more patrols being send there, and so on.</p>
</div>
<div class="section" id="when-to-use-and-not-to-use-machine-learning">
<h3>When to use and not to use machine learning<a class="headerlink" href="#when-to-use-and-not-to-use-machine-learning" title="Permalink to this headline">¶</a></h3>
<p>As you might be able to tell by the existance of this book, I’m excited about machine learning and an avid advocate. However, I think it is cruicial to not fall victim to hype, and carefully consider whether a particular situation calls for a machine learning solution. Many machine learning practitioners get caught up in the (fascinating) details of algorithms and datasets, but lose perspective of the bigger picture. To the data scientist with a machine learning hammer, too often everything looks like a classification nail.
In general, I would recommend restricting yourself to supervised learning in most practical settings; in other words, if you do not have a training dataset for which you know the outcome, it will be very hard to create an effective solution. As mentioned before, machine learning will be most useful for making individual-level predictions, not for inference. I also already laid out some prerequisits for using supervised learning in the respective section above.
Let’s assume all of these criteria are met.</p>
<p>My first advice would be, don’t try machine learning. Machine learning systems are very complex and often fragile. Whether you’re in research or a startup, don’t immediately start with “oh we can apply deep learning to this”. Often it’s good to collect data, and be able to use data to drive and evaluate decisions. But including a complex process like machine learning into whatever you’re trying to do will make it much harder to debug and much harder to understand.</p>
</div>
<div class="section" id="ethics">
<h3>Ethics<a class="headerlink" href="#ethics" title="Permalink to this headline">¶</a></h3>
<p>One aspect of machine learning that only recently is getting some more attention is ethics. There was a recent article in propublica about racial bias in risk-assessment used in the criminal justice system. Spoiler alert: it’s bad. I recommend reading the article, it’s quite interesting. This is a black-box machine learning system created by some company. If they had to provide explanations, or a more transparent system, the situation would likely be better. But this is not the only place where ethics plays a role in machine learning. There will be a more focused course on ethics in the DSI next semester, and I really recommend looking into it.</p>
<p>Some people think that ethics is not something that the technical people should care about, but I disagree. I think if you build a machine learning system, you should know whether and how it is biased, and whether its application is ethical. Sometimes it’s hard to decide that, though. There’s an example of two high-schools, both of whom tried to predict which of their students will underperform in the coming year. There is a lot of ways this could be biased based on race, financial background and other factors. But that’s not the point. The point is that one of the schools used the predictions, and kicked out these students before the annual evaluation, so that they got a better evaluation score. The other school used the data to provide these students with targeted support and help. The algorithm could be the same, but the outcome is quite different. Ok, that’s enough about ethics, I hope you’ll keep these considerations in mind. The next thing I want to talk about is data!</p>
</div>
<div class="section" id="explainable-ai">
<h3>Explainable AI<a class="headerlink" href="#explainable-ai" title="Permalink to this headline">¶</a></h3>
</div>
<div class="section" id="scaling-up">
<h3>Scaling up<a class="headerlink" href="#scaling-up" title="Permalink to this headline">¶</a></h3>
<p>There’s another aspect to data collection and dataset size. More data might be more expensive to collect, but it might also be more expensive and more complicated to work with. With the available cloud services, storage might not be that much of an issue any more. But runtime is. And I’m less concerned about buying a bigger cluster, I’m more concerned about your time, the data scientists time and the machine learning analysis. There’s a reason we’ll be using Python in this course. Python is easy to learn, has lots of tools and allows very close interactions with the data. If we would try to use SPARK instead, this would be whole other story. Working with distributed systems is hard, they are not responsive and the tooling is often not as good. So what I often do, no matter how big the dataset is, is to work with a subset of the data that fits into my RAM. Then I can use python, and everything is easy. And with AWS, I can easily get 512GB of RAM, if I really need to. Arguably I’m a bit biased because I work on scikit-learn. For some applications that subsampling might not make sense, or working on very large data is critical. But I don’t think that should ever be the first step.</p>
</div>
<div class="section" id="the-machine-learning-process">
<h3>The machine learning process<a class="headerlink" href="#the-machine-learning-process" title="Permalink to this headline">¶</a></h3>
<p>the circle of life…</p>
<div class="toctree-wrapper compound">
</div>
</div>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="../index.html" title="previous page">Welcome</a>
    <a class='right-next' id="next-link" href="01-preliminaries.html" title="next page">Prerequisits and required libraries</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Andreas C. Müller<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>


<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Imputation &#8212; Applied Machine Learning in Python</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .secondtoggle, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Algorithm Chains and Pipelines" href="09-pipeline.html" />
    <link rel="prev" title="Feature Engineering" href="05-feature-engineering.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Applied Machine Learning in Python</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../index.html">1. Welcome</a>
  </li>
  <li class="">
    <a href="../00-introduction/00-introduction.html">2. Introduction</a>
  </li>
  <li class="active">
    <a href="00-ml-workflow.html">3. The Machine Learning Workflow</a>
  <ul class="nav sidenav_l2">
    <li class="">
      <a href="01-data-loading.html">3.1 Data Loading</a>
    </li>
    <li class="">
      <a href="02-supervised-learning.html">3.2 Supervised learning with scikit-learn</a>
    </li>
    <li class="">
      <a href="03-preprocessing.html">3.3 Preprocessing and Scaling</a>
    </li>
    <li class="">
      <a href="04-categorical-variables.html">3.4 Categorical Variables</a>
    </li>
    <li class="">
      <a href="05-feature-engineering.html">3.5 Feature Engineering</a>
    </li>
    <li class="active">
      <a href="">3.6 Imputation</a>
    </li>
    <li class="">
      <a href="09-pipeline.html">3.7 Algorithm Chains and Pipelines</a>
    </li>
    <li class="">
      <a href="10-cross-validation-grid-search.html">3.8 Cross-validation and Grid Search</a>
    </li>
  </ul>
  </li>
  <li class="">
    <a href="../02-supervised-learning/index.html">4. Supervised Learning Algorithms</a>
  </li>
  <li class="">
    <a href="../03-unsupervised-learning/index.html">5. Unsupervised Learning Algorithms</a>
  </li>
  <li class="">
    <a href="../04-model-evaluation/index.html">6. Model Evaluation</a>
  </li>
  <li class="">
    <a href="../05-advanced-topics/index.html">7. Advanced Topics</a>
  </li>
</ul>
</nav>
<p class="navbar_footer">Powered by <a href="https://jupyterbook.org">Jupyter Book</a></p>
</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse" data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu" aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation" title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i class="fas fa-download"></i></button>

            
            <div class="dropdown-buttons">
                <!-- ipynb file if we had a myst markdown file -->
                
                <!-- Download raw file -->
                <a class="dropdown-buttons" href="../_sources/01-ml-workflow/08-imputation.ipynb.txt"><button type="button" class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip" data-placement="left">.ipynb</button></a>
                <!-- Download PDF via print -->
                <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF" onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
            </div>
            
        </div>

        <!-- Edit this page -->
        

        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
            <div class="dropdown-buttons">
                
                <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/01-ml-workflow/08-imputation.ipynb"><button type="button" class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip" data-placement="left"><img class="binder-button-logo" src="../_static/images/logo_binder.svg" alt="Interact on binder">Binder</button></a>
                
                
                
            </div>
        </div>
        
    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#dealing-with-missing-values" class="nav-link">Dealing with missing values</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#imputation-methods" class="nav-link">Imputation Methods</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#baseline-dropping-columns" class="nav-link">Baseline: Dropping Columns</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#mean-and-median" class="nav-link">Mean and Median</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#knn-imputation" class="nav-link">KNN Imputation</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#model-driven-imputation" class="nav-link">Model-Driven Imputation</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#comparision-of-imputation-methods" class="nav-link">Comparision of Imputation Methods</a>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="imputation">
<h1>Imputation<a class="headerlink" href="#imputation" title="Permalink to this headline">¶</a></h1>
<p>class: spacious</p>
<div class="section" id="dealing-with-missing-values">
<h2>Dealing with missing values<a class="headerlink" href="#dealing-with-missing-values" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Missing values can be encoded in many ways</p></li>
<li><p>Numpy has no standard format for it (often np.NaN) - pandas does</p></li>
<li><p>Sometimes: 999,
, ?, np.inf, “N/A”, “Unknown“ …</p></li>
<li><p>Not discussing “missing output” - that’s semi-supervised learning.</p></li>
<li><p>Often missingness is informative (Use <code class="docutils literal notranslate"><span class="pre">MissingIndicator</span></code>)</p></li>
</ul>
<p>So first we’re going to talk about imputation, which means
basically dealing with missing values. Before that, we’re
going to talk about different methods to deal with missing
values. The first thing about missing values is that you
need to figure out whether your dataset has them and how
they encode it. If you’re on Python, numpy has no standard
way to represent missing values while Pandas does and it’s
usually nan. But the problem is usually more in the data
source. So depending on where your data comes from, missing
values might be encoded as anything. They might be
differently encoded for different parts of the data set. So
if you see some question marks somewhere, it doesn’t mean
that all missing values are encoded as question marks. There
might be different reasons why data is missing. If you look
into like theoretical analysis missingness, often there you
can see something that’s called missing at random or missing
completely at random, meaning that data was retracted
randomly from the dataset. That’s not usually what happens.
Usually, if the data is missing, it’s missing because
something when differently in a process, like someone didn’t
fill out the form correctly, or someone didn’t reply in a
survey. And very often the fact that someone didn’t reply or
that something was not measured is actually informative.
Whenever you have missing values, it’s often a good idea to
keep the information about whether the value was missing or
not. If a feature was missing, while we’re going to do
imputation and we’re going to try to fill in the missing
values. It’s often really useful information that’s
something was missing and you should record the fact and
represent it in the dataset somehow. We’re only going to
talk about missing input today. You can also have missing
values in the outputs that are usually called
semi-supervised learning where you have the true target or
the true class only for some data points, but not for all of
them. So there’s the first method which is very obvious.
Let’s say your data looks like this. All my illustrations
today we’ll be adding randomness to the iris data set.</p>
<p>FIXME: Better digram for feature selection. What are the
hypothesises for the tests</p>
<p>.center[
<img alt=":scale 80%" src="../_images/row_nan_col_nan.png" />
]</p>
<p>So if my dataset looks like something on the left-hand side
here, then you can see that there are only missing values in
the first feature and it’s mostly missing. One of the ways
to deal with this is just completely dropped the first
feature, and that might be a reasonable thing to do. If
there are so few values here that you don’t think there’s
any information in this just drop it I always like to
compare everything to a baseline approach. So your baseline
approach should be if there’s only missing values in some of
the columns, just drop these columns, see what happens. You
can always iterate and improve on that but that should be
the baseline. A little bit trickier situation is that there
might be some missing values only for a few rows, the rows
are data points. You can kick out these data points and
train the model on the rest and that might be fine. There’s
a bit of a problem with this though, that if you want to
make predictions on new data and the data that arrives has
missing values you’ll not be able to make predictions
because you don’t have a way to deal with missing values. If
you’re guaranteed that any new test point that comes in will
not have missing values then doing this might make sense.
Another issue with dropping the rows with missing values is
that if this was related to the actual outcome then it might
be that you biased how well you think you’re doing. Maybe
all the hard data points are the ones that have missing
values. And so by excluding them from your training data,
you’re also excluding them from the validation. So it means
you think you’re doing very well because you discarded all
the hard data points. Discarding data points is a little bit
trickier and it depends on your situation.</p>
<p>.center[
<img alt=":scale 100%" src="../_images/imputation-schema.png" />
]</p>
<p>The other solution is to impute them. So the idea is that
you have your training data set, you build some model of the
training data set, and then you fill in the missing values
using the information from the other rows and columns. And
you built a model for this and then you can also apply the
same imputation model on the test data set if you want to
make predictions. Question is what if it has all missing
values? Then you have no choice but drop that. If in the
dataset that happens, you need to figure out what you are
going to do. Like, if you have a production system, and
something comes in with all missing values, you need to
decide what you’re going to do. But you probably cannot use
this data point for training model. You could like use the
outputs and train to find the mean outcome of all the values
that are missing.</p>
<p>class: spacious</p>
</div>
<div class="section" id="imputation-methods">
<h2>Imputation Methods<a class="headerlink" href="#imputation-methods" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Mean / Median</p></li>
<li><p>kNN</p></li>
<li><p>Regression models</p></li>
<li><p>Matrix factorization (not in this lecture)</p></li>
</ul>
<p>So let’s talk about the general methods for data imputation.
So these are the ones that we are going to talk through. The
easiest one is me doing a constant value per column.
Imputing the mean or the medium of the column that we’re
trying to compute. kNN means taking the average of KNearest
Neighbors. Regression means I build a regression model from
some of the features trying to rip the missing future. And
finally, elaborate probabilistic models. They try to build a
probabilistic model of the dataset and complete the missing
values based on this probabilistic model</p>
</div>
<div class="section" id="baseline-dropping-columns">
<h2>Baseline: Dropping Columns<a class="headerlink" href="#baseline-dropping-columns" title="Permalink to this headline">¶</a></h2>
<p>.smaller[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegressionCV</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

<span class="n">nan_columns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_drop_columns</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="o">~</span><span class="n">nan_columns</span><span class="p">]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">v</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">X_drop_columns</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<p>0.772
]</p>
<p>Here’s my baseline, which is dropping the columns. I used
iris dataset where I had to put some missing values into the
second and third column. Here, x_score has like some missing
values, I split into test and training test data set and
then I drop all columns that have missing values and then I
can train logistic regression, which is sort of the model
I’m going to use to tell me how well does this imputation
work for classification. For my baseline, using a logistic
regression model and 10 fold baseline, I get 77.2% accuracy.</p>
</div>
<div class="section" id="mean-and-median">
<h2>Mean and Median<a class="headerlink" href="#mean-and-median" title="Permalink to this headline">¶</a></h2>
<p>.center[
<img alt=":scale 100%" src="../_images/imputation-median-schema.png" />
]</p>
<p>The simplest imputation is mean or medium. Unfortunately,
only one is implemented in scikit-learn right now. If this
is our dataset, the imputation will look like this. For a
column, each missing value is replaced by the mean of the
column. The imputer is the only transformer in scikit-learn
that can handle missing data. Using the imputer you can
specify the strategy, mean or median or constant and then
you can call the method transform and that imputes missing
values.</p>
<p>.center[
<img alt=":scale 90%" src="../_images/median_imputation.png" />
]</p>
<p>Here is a graphical illustration of what does this. So the
iris dataset is four-dimensional, and I’m plotting it in two
dimensions in which I added missing values. So, there are
two other dimensions which had no missing values, which you
can’t see. The original data set is basically blue points
here, orange points here, green points here, and it’s
relatively easy to separate. But here you can see that the
green points they have a lot of missingness, so they were
replaced by the mean of the whole dataset.</p>
<p>So there are two things about this. One, I kind of lost the
class information a lot. Two, the data is now in places
where there was no data before, which is not so great. You
could do smart things like doing the mean per class, but
that’s actually not something that I’ve seen a lot.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScalar</span>

<span class="n">nan_columns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">X_drop_columns</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,</span><span class="o">~</span><span class="n">nan_columns</span><span class="p">]</span>
<span class="n">logreg</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScalar</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">X_drop_columns</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<p>0.794</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">mean_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">),</span>
                          <span class="n">StandardScalar</span><span class="p">(),</span>
                          <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">mean_pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<p>0.729</p>
<p>Here’s the comparison of dropping the columns versus doing
the mean amputation. We actually see that the mean
imputation is worse. In general, if you have very few
missing values, it might actually not be so bad and putting
in the mean might work.
Here I basically designed the dataset so that mean imputation fails.
This is not very realistic.</p>
<p>class: spacious</p>
</div>
<div class="section" id="knn-imputation">
<h2>KNN Imputation<a class="headerlink" href="#knn-imputation" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Find k nearest neighbors that have non-missing values.</p></li>
<li><p>Fill in all missing values using the average of the
neighbors.</p></li>
</ul>
<p>FIXME illustration</p>
<p>In terms of complexity is using Nearest Neighbors. So the
idea is for each data point, we find the kNearest neighbors
and then fill in the missing values as the average of the
features of these neighbors. The difficulty here is
measuring distances if there are missing values. If there
are missing values, I can’t just compute Euclidean
distances.</p>
<p>.smaller[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">knn_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">KNNImputer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">0.849</span>
</pre></div>
</div>
<p>]</p>
<p>.center[
<img alt=":scale 60%" src="../_images/knn_imputation.png" />
]</p>
</div>
<div class="section" id="model-driven-imputation">
<h2>Model-Driven Imputation<a class="headerlink" href="#model-driven-imputation" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Train regression model for missing values</p></li>
<li><p>Iterate: retrain after filling in</p></li>
<li><p>IterativeImputer in next sklearn release</p></li>
</ul>
<p>.smaller[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rf_imp</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">(</span><span class="n">predictor</span><span class="o">=</span><span class="n">RandomForestRegressor</span><span class="p">())</span>
<span class="n">rf_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">rf_imp</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf_pipe</span><span class="p">,</span> <span class="n">X_rf_imp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mf">0.845</span>
</pre></div>
</div>
<p>]</p>
<p>The next step up in complexity is using an arbitrary
regression model for imputation. I mean, arguably, the kNN
is also a regression model, but there’s like some
intricacies that make it a little bit different. So the idea
with using a regression model is you do the first pass and
impute data using the mean. And then you try to predict the
missing features using a regression model trained on the
non-missing features and then you iterate this until stuff
doesn’t change anymore. You can use any model you like, and
this is very flexible, and it can be fast if you have a fast
model.</p>
<p>class: spacious</p>
</div>
<div class="section" id="comparision-of-imputation-methods">
<h2>Comparision of Imputation Methods<a class="headerlink" href="#comparision-of-imputation-methods" title="Permalink to this headline">¶</a></h2>
<p>.center[
<img alt=":scale 100%" src="../_images/med_knn_rf_comparison.png" />
]</p>
<p>FIXME better illustration/ graph
Here’s a comparison on the iris dataset again.
This is a very artificial example and is only meant to illustrate the ideas.
In practice, using the mean or median is actually quite decent.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;savefig.dpi&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">300</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;savefig.bbox&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;tight&#39;</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">,</span> <span class="p">(</span><span class="ne">FutureWarning</span><span class="p">,</span> <span class="ne">DeprecationWarning</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="n">iris</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>[&#39;sepal length (cm)&#39;,
 &#39;sepal width (cm)&#39;,
 &#39;petal length (cm)&#39;,
 &#39;petal width (cm)&#39;]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">iris</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">iris</span><span class="o">.</span><span class="n">target</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">shuffle</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="p">[:</span><span class="mi">30</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[7.7 3.8 6.7 2.2]
 [5.7 2.9 4.2 1.3]
 [4.8 3.  1.4 0.3]
 [5.4 3.7 1.5 0.2]
 [4.9 2.5 4.5 1.7]
 [5.5 2.3 4.  1.3]
 [6.4 2.7 5.3 1.9]
 [6.9 3.1 4.9 1.5]
 [5.1 3.4 1.5 0.2]
 [5.1 3.8 1.9 0.4]
 [7.1 3.  5.9 2.1]
 [5.  2.  3.5 1. ]
 [5.1 3.7 1.5 0.4]
 [5.8 2.6 4.  1.2]
 [6.  2.2 4.  1. ]
 [4.8 3.4 1.6 0.2]
 [6.2 3.4 5.4 2.3]
 [5.2 3.5 1.5 0.2]
 [5.2 4.1 1.5 0.1]
 [4.9 3.1 1.5 0.2]
 [5.5 4.2 1.4 0.2]
 [6.7 2.5 5.8 1.8]
 [6.4 2.8 5.6 2.1]
 [5.1 3.5 1.4 0.2]
 [6.7 3.1 4.4 1.4]
 [6.5 3.  5.8 2.2]
 [6.1 3.  4.9 1.8]
 [4.9 3.  1.4 0.2]
 [5.1 3.5 1.4 0.3]
 [6.1 2.9 4.7 1.4]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># a column is mostly missing</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_missing_column</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">19</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">X_missing_column</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">NaN</span>
<span class="n">X_missing_column</span><span class="p">[</span><span class="mi">120</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[nan, 3. , 4.4, 1.4],
       [nan, 2.4, 3.7, 1. ],
       [nan, 2.9, 5.6, 1.8],
       [nan, 3. , 4.5, 1.5],
       [nan, 2.7, 4.9, 1.8],
       [nan, 2.9, 4.3, 1.3],
       [nan, 3.4, 1.6, 0.4],
       [nan, 2.8, 5.1, 2.4],
       [nan, 3.6, 1. , 0.2],
       [nan, 2.8, 4.7, 1.2],
       [7.7, 2.8, 6.7, 2. ],
       [nan, 3. , 4.2, 1.2],
       [nan, 2.7, 3.9, 1.2],
       [nan, 2.6, 4.4, 1.2],
       [nan, 2.5, 4.9, 1.5],
       [nan, 3. , 5.2, 2.3],
       [nan, 3.8, 6.4, 2. ],
       [nan, 3.7, 1.5, 0.2],
       [nan, 2.2, 5. , 1.5],
       [nan, 2.8, 4.6, 1.5],
       [nan, 3.5, 1.3, 0.3],
       [nan, 3.2, 5.9, 2.3],
       [nan, 2.8, 6.1, 1.9],
       [nan, 3.4, 1.4, 0.3],
       [nan, 3.4, 1.5, 0.2],
       [nan, 3. , 1.4, 0.1],
       [nan, 3.9, 1.7, 0.4],
       [nan, 3.2, 4.5, 1.5],
       [nan, 3.3, 1.7, 0.5],
       [nan, 2.8, 4.8, 1.8]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># only a few rows have missing data. but a lot of it</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="n">X_missing_rows</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">rng</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">5</span><span class="p">):</span>
    <span class="n">X_missing_rows</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">rng</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span><span class="o">&gt;</span> <span class="o">.</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">NaN</span>
<span class="n">X_missing_rows</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[7.7, 3.8, 6.7, 2.2],
       [nan, nan, 4.2, 1.3],
       [4.8, 3. , 1.4, 0.3],
       [5.4, 3.7, 1.5, 0.2],
       [4.9, 2.5, 4.5, 1.7],
       [nan, nan, nan, nan],
       [6.4, 2.7, 5.3, 1.9],
       [6.9, 3.1, 4.9, 1.5],
       [5.1, 3.4, 1.5, 0.2],
       [5.1, 3.8, 1.9, 0.4],
       [7.1, 3. , 5.9, 2.1],
       [5. , 2. , 3.5, 1. ],
       [5.1, 3.7, 1.5, 0.4],
       [5.8, 2.6, 4. , 1.2],
       [nan, nan, nan, nan],
       [4.8, 3.4, 1.6, 0.2],
       [6.2, 3.4, 5.4, 2.3],
       [5.2, 3.5, 1.5, 0.2],
       [5.2, 4.1, 1.5, 0.1],
       [4.9, 3.1, 1.5, 0.2],
       [5.5, 4.2, 1.4, 0.2],
       [6.7, 2.5, 5.8, 1.8],
       [6.4, 2.8, 5.6, 2.1],
       [5.1, nan, nan, nan],
       [6.7, 3.1, 4.4, 1.4],
       [6.5, 3. , 5.8, 2.2],
       [nan, nan, nan, 1.8],
       [4.9, 3. , 1.4, 0.2],
       [5.1, 3.5, 1.4, 0.3],
       [6.1, 2.9, 4.7, 1.4]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">[</span><span class="n">y</span><span class="o">==</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([6.588, 2.974, 5.552, 2.026])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># some values missing only</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_some_missing</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">5.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=.</span><span class="mi">7</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">&lt;</span> <span class="o">.</span><span class="mi">6</span>
<span class="n">X_some_missing</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">NaN</span>
<span class="c1"># different random numbers</span>
<span class="n">mask2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">5.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=.</span><span class="mi">7</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span> <span class="o">&lt;</span> <span class="o">.</span><span class="mi">6</span>
<span class="n">X_some_missing</span><span class="p">[</span><span class="n">mask2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">NaN</span>
<span class="n">X_some_missing</span><span class="p">[:</span><span class="mi">30</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[7.7, 3.8, 6.7, nan],
       [5.7, 2.9, 4.2, 1.3],
       [4.8, 3. , 1.4, 0.3],
       [5.4, 3.7, 1.5, 0.2],
       [4.9, 2.5, 4.5, 1.7],
       [5.5, 2.3, 4. , 1.3],
       [6.4, 2.7, 5.3, 1.9],
       [6.9, 3.1, nan, nan],
       [5.1, 3.4, 1.5, 0.2],
       [5.1, 3.8, 1.9, 0.4],
       [7.1, 3. , 5.9, nan],
       [5. , 2. , 3.5, 1. ],
       [5.1, 3.7, 1.5, 0.4],
       [5.8, 2.6, 4. , 1.2],
       [6. , 2.2, 4. , 1. ],
       [4.8, 3.4, 1.6, 0.2],
       [6.2, 3.4, 5.4, 2.3],
       [5.2, 3.5, 1.5, 0.2],
       [5.2, 4.1, 1.5, 0.1],
       [4.9, 3.1, 1.5, 0.2],
       [5.5, 4.2, 1.4, 0.2],
       [6.7, 2.5, nan, nan],
       [6.4, 2.8, nan, nan],
       [5.1, 3.5, 1.4, 0.2],
       [6.7, 3.1, nan, 1.4],
       [6.5, 3. , nan, 2.2],
       [6.1, 3. , nan, 1.8],
       [4.9, 3. , 1.4, 0.2],
       [5.1, 3.5, 1.4, 0.3],
       [6.1, 2.9, 4.7, 1.4]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.25333333333333335
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="o">~</span><span class="n">mask2</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([50, 38, 23])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># from now on use X_ = X_some_missing</span>
<span class="n">X_</span> <span class="o">=</span> <span class="n">X_some_missing</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">cross_val_score</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X_</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="n">nan_columns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">X_drop_columns</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="o">~</span><span class="n">nan_columns</span><span class="p">]</span>
<span class="n">logreg</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">logreg</span><span class="p">,</span> <span class="n">X_drop_columns</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.793939393939394
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="p">[</span><span class="o">-</span><span class="mi">30</span><span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>[[6.7 3.1 nan 1.4]
 [7.7 2.8 6.7 2. ]
 [5.7 4.4 1.5 0.4]
 [5.1 3.3 1.7 0.5]
 [4.6 3.4 1.4 0.3]
 [4.8 3.4 1.6 0.2]
 [5.2 4.1 1.5 0.1]
 [5.7 3.  4.2 1.2]
 [7.7 3.  6.1 2.3]
 [7.4 2.8 6.1 nan]
 [7.2 3.6 nan nan]
 [5.1 3.8 1.6 0.2]
 [5.6 2.8 nan 2. ]
 [5.1 3.4 1.5 0.2]
 [6.2 3.4 5.4 2.3]
 [4.6 3.6 1.  0.2]
 [5.6 3.  4.5 1.5]
 [5.4 3.  4.5 1.5]
 [6.1 3.  nan 1.4]
 [6.7 3.  nan nan]
 [4.6 3.1 1.5 0.2]
 [7.9 3.8 6.4 nan]
 [6.5 3.  nan 1.8]
 [4.8 3.  1.4 0.1]
 [5.1 2.5 3.  1.1]
 [6.2 2.2 4.5 nan]
 [5.2 3.4 1.4 0.2]
 [5.7 2.5 nan nan]
 [6.3 2.7 nan nan]
 [6.4 3.2 nan nan]]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">precision</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">SimpleImputer</span>
<span class="n">imp</span> <span class="o">=</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s2">&quot;median&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_median_imp</span> <span class="o">=</span> <span class="n">imp</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_median_imp</span><span class="p">[</span><span class="o">-</span><span class="mi">30</span><span class="p">:]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([[6.7, 3.1, 3.5, 1.4],
       [7.7, 2.8, 6.7, 2. ],
       [5.7, 4.4, 1.5, 0.4],
       [5.1, 3.3, 1.7, 0.5],
       [4.6, 3.4, 1.4, 0.3],
       [4.8, 3.4, 1.6, 0.2],
       [5.2, 4.1, 1.5, 0.1],
       [5.7, 3. , 4.2, 1.2],
       [7.7, 3. , 6.1, 2.3],
       [7.4, 2.8, 6.1, 1.1],
       [7.2, 3.6, 3.5, 1.1],
       [5.1, 3.8, 1.6, 0.2],
       [5.6, 2.8, 3.5, 2. ],
       [5.1, 3.4, 1.5, 0.2],
       [6.2, 3.4, 5.4, 2.3],
       [4.6, 3.6, 1. , 0.2],
       [5.6, 3. , 4.5, 1.5],
       [5.4, 3. , 4.5, 1.5],
       [6.1, 3. , 3.5, 1.4],
       [6.7, 3. , 3.5, 1.1],
       [4.6, 3.1, 1.5, 0.2],
       [7.9, 3.8, 6.4, 1.1],
       [6.5, 3. , 3.5, 1.8],
       [4.8, 3. , 1.4, 0.1],
       [5.1, 2.5, 3. , 1.1],
       [6.2, 2.2, 4.5, 1.1],
       [5.2, 3.4, 1.4, 0.2],
       [5.7, 2.5, 3.5, 1.1],
       [6.3, 2.7, 3.5, 1.1],
       [6.4, 3.2, 3.5, 1.1]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_median_imp</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(112, 4)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.patches</span> <span class="k">as</span> <span class="nn">patches</span>
<span class="n">imputed_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">X_train</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">plot_imputation</span><span class="p">(</span><span class="n">X_imp</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># helper function to plot imputed data points</span>
    <span class="k">if</span> <span class="n">ax</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_imp</span><span class="p">[</span><span class="n">imputed_mask</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">X_imp</span><span class="p">[</span><span class="n">imputed_mask</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">tab10</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="n">imputed_mask</span><span class="p">]),</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;s&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_imp</span><span class="p">[</span><span class="o">~</span><span class="n">imputed_mask</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">X_imp</span><span class="p">[</span><span class="o">~</span><span class="n">imputed_mask</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">tab10</span><span class="p">(</span><span class="n">y_train</span><span class="p">[</span><span class="o">~</span><span class="n">imputed_mask</span><span class="p">]),</span> <span class="n">alpha</span><span class="o">=.</span><span class="mi">6</span><span class="p">)</span>
    <span class="c1"># this is for creating the legend...</span>
    <span class="n">square</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Line2D</span><span class="p">((</span><span class="mi">0</span><span class="p">,),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,),</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;s&quot;</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Imputed data&#39;</span><span class="p">)</span>
    <span class="n">circle</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">Line2D</span><span class="p">((</span><span class="mi">0</span><span class="p">,),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,),</span> <span class="n">linestyle</span><span class="o">=</span><span class="s1">&#39;&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s2">&quot;o&quot;</span><span class="p">,</span> <span class="n">markerfacecolor</span><span class="o">=</span><span class="s2">&quot;w&quot;</span><span class="p">,</span> <span class="n">markeredgecolor</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;Real data&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="n">iris</span><span class="o">.</span><span class="n">feature_names</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="p">[</span><span class="n">square</span><span class="p">,</span> <span class="n">circle</span><span class="p">],</span> <span class="n">numpoints</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">)</span>

<span class="n">plot_imputation</span><span class="p">(</span><span class="n">X_median_imp</span><span class="p">,</span> <span class="s2">&quot;Median imputation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;images/median_imputation.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/08-imputation_31_0.png" src="../_images/08-imputation_31_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># I designed the problem so that mean imputation wouldn&#39;t work</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">median_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span><span class="o">=</span><span class="s1">&#39;median&#39;</span><span class="p">),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">median_pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.7772727272727271
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="model-driven-imputation-and-knn">
<h1>Model-driven imputation and KNN<a class="headerlink" href="#model-driven-imputation-and-knn" title="Permalink to this headline">¶</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">KNNImputer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">knnimp</span> <span class="o">=</span> <span class="n">KNNImputer</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_train_knn</span> <span class="o">=</span> <span class="n">knnimp</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">plot_imputation</span><span class="p">(</span><span class="n">X_train_knn</span><span class="p">,</span> <span class="s2">&quot;KNN imputation&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;images/knn_imputation.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/08-imputation_37_0.png" src="../_images/08-imputation_37_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">knn_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">KNNImputer</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">knn_pipe</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.8825757575757575
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_iterative_imputer</span>
<span class="kn">from</span> <span class="nn">sklearn.impute</span> <span class="kn">import</span> <span class="n">IterativeImputer</span>

<span class="n">rfimp</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">RandomForestRegressor</span><span class="p">())</span>
<span class="n">rfimp</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">X_rf_imp</span> <span class="o">=</span> <span class="n">rfimp</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="stderr docutils container">
<pre class="stderr literal-block">/home/andy/checkout/scikit-learn/sklearn/impute/_iterative.py:608: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.
  &quot; reached.&quot;, ConvergenceWarning)
</pre>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">plot_imputation</span><span class="p">(</span><span class="n">X_median_imp</span><span class="p">,</span> <span class="s2">&quot;Median&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plot_imputation</span><span class="p">(</span><span class="n">X_train_knn</span><span class="p">,</span> <span class="s2">&quot;KNN&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plot_imputation</span><span class="p">(</span><span class="n">X_rf_imp</span><span class="p">,</span> <span class="s2">&quot;Random Forest imputation&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s2">&quot;images/med_knn_rf_comparison.png&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/08-imputation_40_0.png" src="../_images/08-imputation_40_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">rf_imp</span> <span class="o">=</span> <span class="n">IterativeImputer</span><span class="p">(</span><span class="n">estimator</span><span class="o">=</span><span class="n">RandomForestRegressor</span><span class="p">())</span>
<span class="n">rf_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">rf_imp</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">rf_pipe</span><span class="p">,</span> <span class="n">X_rf_imp</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.8924242424242423
</pre></div>
</div>
</div>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="05-feature-engineering.html" title="previous page">Feature Engineering</a>
    <a class='right-next' id="next-link" href="09-pipeline.html" title="next page">Algorithm Chains and Pipelines</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Andreas C. Müller<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>
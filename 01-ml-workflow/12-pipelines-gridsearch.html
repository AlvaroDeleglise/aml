

<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>More on Pipelines &#8212; Applied Machine Learning in Python</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .secondtoggle, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Supervised Learning Algorithms" href="../02-supervised-learning/index.html" />
    <link rel="prev" title="Model evaluation" href="10-model-validation-and-tuning.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Applied Machine Learning in Python</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../index.html">1. Welcome</a>
  </li>
  <li class="">
    <a href="../00-introduction/00-introduction.html">2. Introduction</a>
  </li>
  <li class="active">
    <a href="00-ml-workflow.html">3. The Machine Learning Workflow</a>
  <ul class="nav sidenav_l2">
    <li class="">
      <a href="01-data-loading.html">3.1 Data Loading and Basic Preprocessing</a>
    </li>
    <li class="">
      <a href="02-supervised-learning.html">3.2 Supervised learning</a>
    </li>
    <li class="">
      <a href="03-preprocessing.html">3.3 Preprocessing and Scaling</a>
    </li>
    <li class="">
      <a href="04-categorical-variables.html">3.4 Categorical Variables</a>
    </li>
    <li class="">
      <a href="08-imputation.html">3.5 Missing Values</a>
    </li>
    <li class="">
      <a href="10-model-validation-and-tuning.html">3.6 Model evaluation</a>
    </li>
    <li class="active">
      <a href="">3.7 More on Pipelines</a>
    </li>
  </ul>
  </li>
  <li class="">
    <a href="../02-supervised-learning/index.html">4. Supervised Learning Algorithms</a>
  </li>
  <li class="">
    <a href="../03-unsupervised-learning/index.html">5. Unsupervised Learning Algorithms</a>
  </li>
  <li class="">
    <a href="../04-model-evaluation/index.html">6. Model Evaluation</a>
  </li>
  <li class="">
    <a href="../05-advanced-topics/index.html">7. Advanced Topics</a>
  </li>
</ul>
</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse" data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu" aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation" title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i class="fas fa-download"></i></button>

            
            <div class="dropdown-buttons">
                <!-- ipynb file if we had a myst markdown file -->
                
                <!-- Download raw file -->
                <a class="dropdown-buttons" href="../_sources/01-ml-workflow/12-pipelines-gridsearch.ipynb.txt"><button type="button" class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip" data-placement="left">.ipynb</button></a>
                <!-- Download PDF via print -->
                <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF" onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
            </div>
            
        </div>

        <!-- Source interaction buttons -->
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
            <div class="dropdown-buttons sourcebuttons">
                <a class="repository-button" href="https://github.com/executablebooks/jupyter-book"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left" title="Source repository"><i class="fab fa-github"></i>repository</button></a>
                <a class="issues-button" href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F01-ml-workflow/12-pipelines-gridsearch.html&body=Your%20issue%20content%20here."><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left" title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
                
            </div>
        </div>
        

        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
            <div class="dropdown-buttons">
                
                <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/01-ml-workflow/12-pipelines-gridsearch.ipynb"><button type="button" class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip" data-placement="left"><img class="binder-button-logo" src="../_static/images/logo_binder.svg" alt="Interact on binder">Binder</button></a>
                
                
                
            </div>
        </div>
        
    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#data-leakage-a-common-error" class="nav-link">Data leakage: a common error</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#automatic-univariate-feature-selection" class="nav-link">Automatic univariate feature selection</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#pipeline-and-gridsearchcv" class="nav-link">Pipeline and GridSearchCV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#setting-estimators-with-gridsearchcv" class="nav-link">Setting Estimators with GridSearchCV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#searching-lists-of-grids" class="nav-link">Searching Lists of Grids</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#accessing-attributes-in-grid-searched-pipeline" class="nav-link">Accessing attributes in grid-searched pipeline</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#todo-columntransformer-also" class="nav-link">TODO ColumnTransformer also?</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#summary" class="nav-link">Summary</a>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="more-on-pipelines">
<h1>More on Pipelines<a class="headerlink" href="#more-on-pipelines" title="Permalink to this headline">¶</a></h1>
<p>We already saw how pipelines can make our live easier in chapter todo. However, when using model evaluation tools such as cross_validate and GridSearchCV, using pipelines becomes essential for obtaining valid results.
Also, the use of pipelines in GridSearchCV allows for a variety of powerful use-cases. We’ll explore both of these in this chapter.</p>
<div class="section" id="data-leakage-a-common-error">
<h2>Data leakage: a common error<a class="headerlink" href="#data-leakage-a-common-error" title="Permalink to this headline">¶</a></h2>
<p>Let’s start with an error that’s commonly made when using cross-validation, which is to leak information from the validation parts of the data.
This is an error that has been made, not only countless times by beginning data scientists, but in several published scientific research articles.
When doing any preprocessing, it is essential that the preprocessing happens within cross-validation, not outside of it.
While we haven’t seen the details of feature selection yet, it provides and excellent example, and so we’ll quickly go over it.</p>
<div class="section" id="automatic-univariate-feature-selection">
<h3>Automatic univariate feature selection<a class="headerlink" href="#automatic-univariate-feature-selection" title="Permalink to this headline">¶</a></h3>
<p>When working with high dimensional datasets, it can be beneficial to work with only a subset of the features. This will reduce the computational burden, increase interpretability, and in some cases can even improve generalization performance.
There are several methods for automating this process, which we will discuss in depth in chapter todo. One of the simplest methods of automatic feature selection is using univariate statistics to rank features.
Univariate means we are looking only at one feature at a time, and evaluate its relationship with the target, often with a simple statistical measure such as an F test or t-test.
We can then rank all the features by the strength of their response (or alternatively by how significant their association with the target was) and select the ones deemed most important.
A version of this is implemented in the <code class="docutils literal notranslate"><span class="pre">SelectPercentile</span></code> transformer in scikit-learn, which allows you to keep a fixed percentage of the existing features.
This can be a quick and easy way to subselect features from a very wide dataset and is commonly used. Here is a quick example on the breast cancer dataset:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectPercentile</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>

<span class="c1"># load the dataset and split it into training and test set</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span>  <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>(426, 30)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a standard pipeline out of scaler and classifier</span>
<span class="n">pipe_knn</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">KNeighborsClassifier</span><span class="p">())</span>
<span class="c1"># Fit and evaluate as a baseline</span>
<span class="n">pipe_knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">pipe_knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.958041958041958
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># create a pipeline subselecting 20% of the features according to univariate statistics</span>
<span class="c1"># Order of scaling and selection does not matter in this case</span>
<span class="n">pipe_select</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">SelectPercentile</span><span class="p">(</span><span class="n">percentile</span><span class="o">=</span><span class="mi">20</span><span class="p">),</span> <span class="n">KNeighborsClassifier</span><span class="p">())</span>
<span class="c1"># Fit the pipeline</span>
<span class="n">pipe_select</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="c1"># slice off the classifier, look at shape of transformed data:</span>
<span class="n">pipe_select</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>(426, 6)
</pre></div>
</div>
</div>
</div>
<p>As expected, of the 30 original features, <code class="docutils literal notranslate"><span class="pre">SelectPercentile</span></code> only kept 20%, meaning 6. Now let’s evaluate the whole pipeline:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pipe_select</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>0.958041958041958
</pre></div>
</div>
</div>
</div>
<p>The performance using only 20% of the features is actually identical to the performance when using all the features, but might be much more interpretable.
We can see which features were selected by TODO.</p>
<p>Now, that we have familiarized ourselves with how SelectPercentile works (at least in general terms), let’s look at the example mentioned above.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># TODO hide</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10000</span><span class="p">))</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">100</span><span class="p">,))</span> <span class="o">&gt;</span> <span class="mi">0</span>
</pre></div>
</div>
</div>
</div>
<p>Say someone gave you a binary classification dataset like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="c1"># count appearances of 0 and 1 in y</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>(100, 10000) (100,)
[53 47]
</pre></div>
</div>
</div>
</div>
<p>It’s very wide, meaning it has many features, compared to the number of samples. This is quite common in sensor networks or in biomedical data for example.
Given the small size of the dataset, we might want to use cross-validation to assess performance, instead of using a single train-test split.
One might start like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># select most informative 5% of features</span>
<span class="n">select</span> <span class="o">=</span> <span class="n">SelectPercentile</span><span class="p">(</span><span class="n">percentile</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">select</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">X_selected</span> <span class="o">=</span> <span class="n">select</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_selected</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>(100, 500)
</pre></div>
</div>
</div>
</div>
<p>Now the dataset seems much more managable at 500 features (which are arguably still a lot), and we can evaluate our model with <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="c1"># run cross-validation with the subselected features</span>
<span class="n">cross_val_score</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">X_selected</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([1., 1., 1., 1., 1.])
</pre></div>
</div>
</div>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>If a model looks too good to be true, an experienced data scientist ususally looks for the mistake. Often it’s a case of information leakage,
so if you ever observe very high accuracy, you might do well to be skeptical at first.</p>
</div>
<p>It looks like it’s our lucky day: we created a model that classifies our dataset perfectly across all folds. From this evaluation, we might be quite certain we found a good model.
However, we made a mistake: we applied the feature selection procedure outside of the cross-validation. We should apply it inside the cross-validation instead.
In scikit-learn, we can easily do that using a pipeline (as we did above).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">SelectPercentile</span><span class="p">(</span><span class="n">percentile</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span> <span class="n">KNeighborsClassifier</span><span class="p">())</span>
<span class="c1"># run cross-validation on the original dataset using the pipeline</span>
<span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([0.45, 0.5 , 0.5 , 0.5 , 0.7 ])
</pre></div>
</div>
</div>
</div>
<p>If we use the proper evaluation technique, our results change drastically: our model is around chance performance for a balanced dataset as this, in other words, we might conclude that the model didn’t learn anything.
Where does this dramatic difference come from? When we called <code class="docutils literal notranslate"><span class="pre">fit</span></code> on <code class="docutils literal notranslate"><span class="pre">SelectPercentile</span></code> before the cross-validation, it had access to the full dataset, which includes the training and test parts for each of the splits. This means it could extract information from all parts of the data, even those that we meant to use as validation set during cross-validation. This is a classical example of information leakage, and a good reason to always use pipelines!</p>
<p>To make the difference in the computation a bit more apparent, I wrote down a more explicit version of the same computation, not using <code class="docutils literal notranslate"><span class="pre">cross_val_score</span></code> or <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> (we’re using <code class="docutils literal notranslate"><span class="pre">KFold</span></code> here which is a way to get the indices to perform K-fold cross-validation, we’ll see this in more detail in TODO):</p>
<table class="table">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>preprocessing before cross validation</p></th>
<th class="head"><p>preprocessing within cross validation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># BAD!</span>
<span class="n">select</span> <span class="o">=</span> <span class="n">SelectPercentile</span><span class="p">(</span><span class="n">percentile</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">select</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># includes the cv test parts!</span>
<span class="n">X_sel</span> <span class="o">=</span> <span class="n">select</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">KFold</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sel</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_sel</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>
    <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># GOOD!</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">select</span> <span class="o">=</span> <span class="n">SelectPercentile</span><span class="p">(</span><span class="n">percentile</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">KFold</span><span class="p">()</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">select</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
    <span class="n">X_sel_train</span> <span class="o">=</span> <span class="n">select</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_sel_train</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">])</span>
    <span class="n">X_sel_test</span> <span class="o">=</span> <span class="n">select</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_sel_test</span><span class="p">,</span> <span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">])</span>
    <span class="n">scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
</pre></div>
</div>
</td>
</tr>
<tr class="row-odd"><td><p>equivalent to:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">select</span> <span class="o">=</span> <span class="n">SelectPercentile</span><span class="p">(</span><span class="n">percentile</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">X_selected</span> <span class="o">=</span> <span class="n">select</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</td>
<td><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">SelectPercentile</span><span class="p">(</span><span class="n">percentile</span><span class="o">=</span><span class="mi">5</span><span class="p">),</span>
                     <span class="n">KNeighborsClassifier</span><span class="p">()</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</td>
</tr>
</tbody>
</table>
<p>If we want to estimate the generalization capability of our model, only the code on the right-hand side will give us the correct solution, and only this result will reflect how well the model will perform on new data. As a matter of fact, <strong>the data in <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> was generated completely at random, and there was no relationship between the two</strong>|. Using the procedure on the left-hand side allowed <code class="docutils literal notranslate"><span class="pre">SelectPercentile</span></code> to find some of the completely random features that happened to be related to the target, looking at the full dataset, including the validation part in each split. This is where information leaked. Using the procedure on the right-hand side, the feature selection could only select features based on the properties of the training part of the split. Features that had an accidental relationship on the training parts do not necessarily contain any information on the test parts, and so the performance of the model is estimated <em>correctly</em> to be at chance level.</p>
<p>Hopefully will convince you to use <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> in all your your work, in particular when using cross-validation. However, if we want to use a <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> within <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> (which you definitely should!), we have to adjust our code a bit.</p>
</div>
</div>
<div class="section" id="pipeline-and-gridsearchcv">
<h2>Pipeline and GridSearchCV<a class="headerlink" href="#pipeline-and-gridsearchcv" title="Permalink to this headline">¶</a></h2>
<p>Remember that when using <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> for tuning hyper-parameters, we pass the estimator together with a dictionary of parameter values.
If we pass a <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> as the estimator, we need to ensure that the parameters we want to tune are applied to the correct step of the pipeline. In principle, there could be several steps of the pipeline having identical hyper-parameter names.
The way to specify the hyperparmeters within a <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> it to address it by the name of the step of the pipeline, followed by a double underscore (known as ‘dunder’ in Python), followed by the name of the hyper-parameter. So if we created a pipeline with <code class="docutils literal notranslate"><span class="pre">make_pipeline</span></code>,
and we want to tune the <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> parameter in <code class="docutils literal notranslate"><span class="pre">KNeighbors</span></code>, we need to use <code class="docutils literal notranslate"><span class="pre">kneighbors__n_neighbors</span></code> as the hyper-parameter name; remember, the when using <code class="docutils literal notranslate"><span class="pre">make_pipeline</span></code>, the name that is assigned to each step is the lower-cased class name. Tuning the <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> parameter on the breast cancer dataset could therefore look like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="c1"># Load the dataset</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span>  <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># create a pipeline</span>
<span class="n">knn_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">KNeighborsClassifier</span><span class="p">())</span>
<span class="c1"># create the search grid.</span>
<span class="c1"># Pipeline hyper-parameters are specified as &lt;step name&gt;__&lt;hyper-parameter name&gt;</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kneighborsclassifier__n_neighbors&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)}</span>
<span class="c1"># Instantiate grid-search</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">knn_pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># run the grid-search and report results</span>
<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;kneighborsclassifier__n_neighbors&#39;: 8}
0.965034965034965
</pre></div>
</div>
</div>
</div>
<div class="highlight-Note notranslate"><div class="highlight"><pre><span></span>You can always check the available hyper-parameters of any model by calling the ``get_params`` method:

```python
knn_pipe = make_pipeline(StandardScaler(), KNeighborsClassifier())
knn_pipe.get_params()
```
```
{&#39;memory&#39;: None,
 &#39;steps&#39;: [(&#39;standardscaler&#39;, StandardScaler()),
  (&#39;kneighborsclassifier&#39;, KNeighborsClassifier())],
 &#39;verbose&#39;: False,
 &#39;standardscaler&#39;: StandardScaler(),
 &#39;kneighborsclassifier&#39;: KNeighborsClassifier(),
 &#39;standardscaler__copy&#39;: True,
 &#39;standardscaler__with_mean&#39;: True,
 &#39;standardscaler__with_std&#39;: True,
 &#39;kneighborsclassifier__algorithm&#39;: &#39;auto&#39;,
 &#39;kneighborsclassifier__leaf_size&#39;: 30,
 &#39;kneighborsclassifier__metric&#39;: &#39;minkowski&#39;,
 &#39;kneighborsclassifier__metric_params&#39;: None,
 &#39;kneighborsclassifier__n_jobs&#39;: None,
 &#39;kneighborsclassifier__n_neighbors&#39;: 5,
 &#39;kneighborsclassifier__p&#39;: 2,
 &#39;kneighborsclassifier__weights&#39;: &#39;uniform&#39;}
```
</pre></div>
</div>
<p>Having a Pipeline inside GridSearchCV also allows us to tune hyper-parameters of the preprocessing steps. Say we want to tune how many feature we want to select in SelectPercentile, we can do it as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># create a pipeline</span>
<span class="n">select_pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">SelectPercentile</span><span class="p">(),</span> <span class="n">KNeighborsClassifier</span><span class="p">())</span>
<span class="c1"># create the search grid.</span>
<span class="c1"># Pipeline hyper-parameters are specified as &lt;step name&gt;__&lt;hyper-parameter name&gt;</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kneighborsclassifier__n_neighbors&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
              <span class="s1">&#39;selectpercentile__percentile&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>
<span class="c1"># Instantiate grid-search</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">select_pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="c1"># run the grid-search and report results</span>
<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;kneighborsclassifier__n_neighbors&#39;: 8, &#39;selectpercentile__percentile&#39;: 100}
0.965034965034965
</pre></div>
</div>
</div>
</div>
<p>As you know, the when specifying multiple hyper-parameters, <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> tries out all possible combinations, so <code class="docutils literal notranslate"><span class="pre">9</span> <span class="pre">*</span> <span class="pre">6</span> <span class="pre">=</span> <span class="pre">54</span> </code> different combinations where tried in this code.
The result is that keepign all features leads to the best result; this is not very surprising, as our motivation for removing features is usually not improving the accuracy, and if we do feature selection at all, we might be interested in trading off simplicity of the model and generalization ability.</p>
</div>
<div class="section" id="setting-estimators-with-gridsearchcv">
<h2>Setting Estimators with GridSearchCV<a class="headerlink" href="#setting-estimators-with-gridsearchcv" title="Permalink to this headline">¶</a></h2>
<p>We can even go one step further and select what preprocessing to include or what model to apply. As a simple example, if we’re unsure whether <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> or <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> is more appropriate for our dataset, we could just have <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> figure that out for us.
After declaring a <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> object, each step becomes a hyper-parameter to which we can assign an estimator of our choice. It might be more natural in this case to name the steps of our pipeline manually, though you don’t have to.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="c1"># declare a two step pipeline, explicitly giving names to both steps.</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s1">&#39;scaler&#39;</span><span class="p">,</span> <span class="n">StandardScaler</span><span class="p">()),</span> <span class="p">(</span><span class="s1">&#39;knn&#39;</span><span class="p">,</span> <span class="n">KNeighborsClassifier</span><span class="p">())])</span>
<span class="c1"># The name of the first step is &#39;scaler&#39; and we can assign different</span>
<span class="c1"># estimators to this step, such as MinMaxScaler or StandardScaler</span>
<span class="c1"># There is a special value &#39;passthrough&#39; which skips the step</span>
<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;scaler&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">MinMaxScaler</span><span class="p">(),</span> <span class="n">StandardScaler</span><span class="p">(),</span> <span class="s1">&#39;passthrough&#39;</span><span class="p">],</span>
              <span class="c1"># we named the second step knn, so we have to use that name here</span>
              <span class="s1">&#39;knn__n_neighbors&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)}</span>
<span class="c1"># instantiate and run as before:</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-none notranslate"><div class="highlight"><pre><span></span>{&#39;knn__n_neighbors&#39;: 8, &#39;scaler&#39;: StandardScaler()}
0.965034965034965
</pre></div>
</div>
</div>
</div>
<div class="margin sidebar">
<p class="sidebar-title"></p>
<p>The initial value of ‘scaler’ from the declaration of <code class="docutils literal notranslate"><span class="pre">pipe</span></code> is not actually used. Scikit-learn requires us to provide a placeholder, though. We could have also used <code class="docutils literal notranslate"><span class="pre">'passthrough'</span></code> instead of StandardScaler and it wouldn’t make a difference.</p>
</div>
<p>In this case, we didn’t win much, but this is a useful tool for automating model selection. However, keep in mind that each option that you add will add a multiplier to your runtime, as all possible combinations are tried. We’ll revisit this in chapter TODO.</p>
</div>
<div class="section" id="searching-lists-of-grids">
<h2>Searching Lists of Grids<a class="headerlink" href="#searching-lists-of-grids" title="Permalink to this headline">¶</a></h2>
<p>There is a little-known but very useful feature in <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> that I want to mention at this point. In fact, <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> can not only search over grids, but also over lists of grids, which are specified as lists of dictionaries.
This comes in handy when trying to search over different preprocessing steps or models which have different hyper-parameters. For example, say we wanted to tune whether the <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> should scale between <code class="docutils literal notranslate"><span class="pre">0</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code> or between <code class="docutils literal notranslate"><span class="pre">-1</span></code> and <code class="docutils literal notranslate"><span class="pre">1</span></code>, while also considering the case if using <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code>. We can’t just add <code class="docutils literal notranslate"><span class="pre">feature_range</span></code> to the <code class="docutils literal notranslate"><span class="pre">param_grid</span></code> dictionary because <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> doesn’t have a <code class="docutils literal notranslate"><span class="pre">feature_range</span></code> parameter. Instead we can create a list of two grids: one grid that always uses <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code> and one that always uses <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code>. This is a bit of a contrived example, but once we know more models and transformers there will be plenty of cases where this comes in handy.</p>
<p>The param_grid could then be specified as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span> <span class="c1"># list of two dicts</span>
    <span class="c1"># first dict always uses MinMaxScaler</span>
    <span class="p">{</span><span class="s1">&#39;scaler&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">MinMaxScaler</span><span class="p">()],</span>
     <span class="c1"># two options for feature_range:</span>
     <span class="s1">&#39;feature_range&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)]},</span>
    <span class="c1"># second dict always uses StandardScaler</span>
    <span class="c1"># there are no options that we&#39;re tuning</span>
    <span class="p">{</span><span class="s1">&#39;scaler&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">StandardScaler</span><span class="p">()]}</span>   
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>There are a couple of points to note here: first, the values for <code class="docutils literal notranslate"><span class="pre">scaler</span></code> always need to be a list, even if it’s a list with a single element. So we can’t specify <code class="docutils literal notranslate"><span class="pre">'scaler':</span> <span class="pre">MinMaxScaler()</span></code>. Second, I left out the tuning of <code class="docutils literal notranslate"><span class="pre">n_neightbors</span></code> here. If we want to tune <code class="docutils literal notranslate"><span class="pre">n_neighbors</span></code> as well as selecting the preprocessing, we need to specify the range for each of the grids, like so:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s1">&#39;scaler&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">MinMaxScaler</span><span class="p">()],</span>
     <span class="s1">&#39;feature_range&#39;</span><span class="p">:</span> <span class="p">[(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)],</span>
     <span class="s1">&#39;knn__n_neighbors&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)},</span>

    <span class="p">{</span><span class="s1">&#39;scaler&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">StandardScaler</span><span class="p">()],</span>
     <span class="s1">&#39;knn__n_neighbors&#39;</span><span class="p">:</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">)}</span>   
<span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>This usage of <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> is a bit more advanced and it doesn’t come up that often, but it’s good to have in your back pocket.</p>
</div>
<div class="section" id="accessing-attributes-in-grid-searched-pipeline">
<h2>Accessing attributes in grid-searched pipeline<a class="headerlink" href="#accessing-attributes-in-grid-searched-pipeline" title="Permalink to this headline">¶</a></h2>
<p>Finally, I want to walk through how you can get to any attributes of your model if it is in a pipeline in a gridsearch.
We have seen all the parts of this already, but it’s a bit involved and so I want to unpack it here.
We fit a <code class="docutils literal notranslate"><span class="pre">grid</span></code> object above, which contained a <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> consisting of a <code class="docutils literal notranslate"><span class="pre">'scaler'</span></code> step and a <code class="docutils literal notranslate"><span class="pre">'knn'</span></code> step.
Now let’s say we want to find out what the mean of the training data was (again, this is a bit contrived but will come handy later for model inspection).
As we learned in chapter TODO, we can get access to the model fitted on the whole training data using the <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code> attribute of <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>GridSearchCV(cv=10,
             estimator=Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
                                       (&#39;knn&#39;, KNeighborsClassifier())]),
             param_grid={&#39;knn__n_neighbors&#39;: range(1, 10),
                         &#39;scaler&#39;: [MinMaxScaler(), StandardScaler(),
                                    &#39;passthrough&#39;]})
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span><span class="o">.</span><span class="n">best_estimator_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;scaler&#39;, StandardScaler()),
                (&#39;knn&#39;, KNeighborsClassifier(n_neighbors=8))])
</pre></div>
</div>
</div>
</div>
<p>As you can see (and might have expected), <code class="docutils literal notranslate"><span class="pre">grid.best_estimator_</span></code> is a pipeline. So if we want to access the scaler, we need to extract the step we’re interested in, for example using <code class="docutils literal notranslate"><span class="pre">[]</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">[</span><span class="s1">&#39;scaler&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>StandardScaler()
</pre></div>
</div>
</div>
</div>
<p>It’s not immediately obvious from the representation in Jupyter, but this is the scaler that was fitted on the whole training dataset. Now if we want to access the <code class="docutils literal notranslate"><span class="pre">mean_</span></code> we can just do so:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># suppress scientific notation, only show two decimal points</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">best_estimator_</span><span class="p">[</span><span class="s1">&#39;scaler&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">mean_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-none notranslate"><div class="highlight"><pre><span></span>array([ 14.12,  19.2 ,  91.89, 654.92,   0.1 ,   0.1 ,   0.09,   0.05,
         0.18,   0.06,   0.4 ,   1.21,   2.86,  40.13,   0.01,   0.03,
         0.03,   0.01,   0.02,   0.  ,  16.21,  25.51, 106.89, 873.72,
         0.13,   0.25,   0.27,   0.11,   0.29,   0.08])
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="todo-columntransformer-also">
<h2>TODO ColumnTransformer also?<a class="headerlink" href="#todo-columntransformer-also" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="summary">
<h2>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">¶</a></h2>
<p>In this chapter we saw the importance of using pipelines to avoid information leakage, in particular when using cross-validation. We also saw how you can combine <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> and <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> to tune your whole workflow with minimal code. Understanding <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> and how it interacts with model validation is critical for working with scikit-learn. Now, you know all of the most important building blocks of scikit-learn, and we have all the tools to start using the different models implemented in scikit-learn.</p>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="10-model-validation-and-tuning.html" title="previous page">Model evaluation</a>
    <a class='right-next' id="next-link" href="../02-supervised-learning/index.html" title="next page">Supervised Learning Algorithms</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Andreas C. Müller<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>


<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Cross-validation and Grid Search &#8212; Applied Machine Learning in Python</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/all.min.css" integrity="sha384-KA6wR/X5RY4zFAHpv/CnoG2UW1uogYfdnP67Uv7eULvTveboZJg0qUpmJZb5VqzN" crossorigin="anonymous">
    <link href="../_static/css/index.css" rel="stylesheet">
    <link rel="stylesheet" href="../_static/sphinx-book-theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/jupyter-sphinx.css" />
    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/mystnb.js"></script>
    <script src="../_static/sphinx-book-theme.js"></script>
    <script >var togglebuttonSelector = '.toggle, .secondtoggle, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Supervised Learning Algorithms" href="../02-supervised-learning/index.html" />
    <link rel="prev" title="Algorithm Chains and Pipelines" href="09-pipeline.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="docsearch:language" content="en">



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Applied Machine Learning in Python</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  
  <ul class="nav sidenav_l1">
  <li class="">
    <a href="../index.html">1. Welcome</a>
  </li>
  <li class="">
    <a href="../00-introduction/00-introduction.html">2. Introduction</a>
  </li>
  <li class="active">
    <a href="00-ml-workflow.html">3. The Machine Learning Workflow</a>
  <ul class="nav sidenav_l2">
    <li class="">
      <a href="01-data-loading.html">3.1 Data Loading</a>
    </li>
    <li class="">
      <a href="02-supervised-learning.html">3.2 Supervised learning with scikit-learn</a>
    </li>
    <li class="">
      <a href="03-preprocessing.html">3.3 Preprocessing and Scaling</a>
    </li>
    <li class="">
      <a href="04-categorical-variables.html">3.4 Categorical Variables</a>
    </li>
    <li class="">
      <a href="05-feature-engineering.html">3.5 Feature Engineering</a>
    </li>
    <li class="">
      <a href="08-imputation.html">3.6 Imputation</a>
    </li>
    <li class="">
      <a href="09-pipeline.html">3.7 Algorithm Chains and Pipelines</a>
    </li>
    <li class="active">
      <a href="">3.8 Cross-validation and Grid Search</a>
    </li>
  </ul>
  </li>
  <li class="">
    <a href="../02-supervised-learning/index.html">4. Supervised Learning Algorithms</a>
  </li>
  <li class="">
    <a href="../03-unsupervised-learning/index.html">5. Unsupervised Learning Algorithms</a>
  </li>
  <li class="">
    <a href="../04-model-evaluation/index.html">6. Model Evaluation</a>
  </li>
  <li class="">
    <a href="../05-advanced-topics/index.html">7. Advanced Topics</a>
  </li>
</ul>
</nav>
<p class="navbar_footer">Powered by <a href="https://jupyterbook.org">Jupyter Book</a></p>
</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse" data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu" aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation" title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i class="fas fa-download"></i></button>

            
            <div class="dropdown-buttons">
                <!-- ipynb file if we had a myst markdown file -->
                
                <!-- Download raw file -->
                <a class="dropdown-buttons" href="../_sources/01-ml-workflow/10-cross-validation-grid-search.ipynb.txt"><button type="button" class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip" data-placement="left">.ipynb</button></a>
                <!-- Download PDF via print -->
                <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF" onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
            </div>
            
        </div>

        <!-- Edit this page -->
        

        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="bottom" onclick="toggleFullScreen()" title="Fullscreen mode"><i class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->
        
        <div class="dropdown-buttons-trigger">
            <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
            <div class="dropdown-buttons">
                
                <a class="binder-button" href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/01-ml-workflow/10-cross-validation-grid-search.ipynb"><button type="button" class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip" data-placement="left"><img class="binder-button-logo" src="../_static/images/logo_binder.svg" alt="Interact on binder">Binder</button></a>
                
                
                
            </div>
        </div>
        
    </div>
    <div class="d-none d-md-block col-md-2 bd-toc show">
<div class="tocsection onthispage pt-5 pb-3">
    <i class="fas fa-list"></i> On this page
</div>

<nav id="bd-toc-nav">
    <ul class="nav section-nav flex-column">
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#cross-validation" class="nav-link">Cross-validation</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#cross-validation-test-set" class="nav-link">Cross-validation + test set</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#grid-search-with-cross-validation" class="nav-link">Grid-Search with Cross-Validation</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#gridsearchcv" class="nav-link">GridSearchCV</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#gridsearchcv-results" class="nav-link">GridSearchCV Results</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#n-neighbors-search-results" class="nav-link">n_neighbors Search Results</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#nested-cross-validation" class="nav-link">Nested Cross-Validation</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#cross-validation-strategies" class="nav-link">Cross-Validation Strategies</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#importance-of-stratification" class="nav-link">Importance of Stratification</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#repeated-kfold-and-leaveoneout" class="nav-link">Repeated KFold and LeaveOneOut</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#defaults-in-scikit-learn" class="nav-link">Defaults in scikit-learn</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#cross-validation-with-non-iid-data" class="nav-link">Cross-Validation with non-iid data</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#grouped-data" class="nav-link">Grouped Data</a><ul class="nav section-nav flex-column">
                
        <li class="nav-item toc-entry toc-h3">
            <a href="#assume-have-data-medical-product-user-from-5-cities" class="nav-link">Assume have data (medical, product, user…) from 5 cities</a>
        </li>
    
        <li class="nav-item toc-entry toc-h3">
            <a href="#usage-scenarios" class="nav-link">Usage Scenarios</a>
        </li>
    
            </ul>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#correlations-in-time-and-or-space" class="nav-link">Correlations in time (and/or space)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#id1" class="nav-link">Correlations in time (and/or space)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#id2" class="nav-link">Correlations in time (and/or space)</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#using-cross-validation-generators" class="nav-link">Using Cross-Validation Generators</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#cross-validate-function" class="nav-link">cross_validate function</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#questions" class="nav-link">Questions ?</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#grid-searches" class="nav-link">Grid Searches</a>
        </li>
    
        <li class="nav-item toc-entry toc-h2">
            <a href="#exercises" class="nav-link">Exercises</a>
        </li>
    
    </ul>
</nav>


    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="cross-validation-and-grid-search">
<h1>Cross-validation and Grid Search<a class="headerlink" href="#cross-validation-and-grid-search" title="Permalink to this headline">¶</a></h1>
<div class="section" id="cross-validation">
<h2>Cross-validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline">¶</a></h2>
<p><img alt=":scale 80%" src="../_images/cross_validation_new.png" /></p>
<p>The answer is of course cross-validation. In cross-validation, you split
your data into multiple folds, usually 5 or 10, and built multiple models.
You start by using fold1 as the test data, and the remaining ones as the
training data. You build your model on the training data, and evaluate
it on the test fold.
For each of the splits of the data, you get a model evaluation and a
score. In the end, you can aggregate the scores, for example by taking
the mean.
What are the pros and cons of this?
Each data point is in the test-set exactly once!
Takes 5 or 10 times longer!
Better data use (larger training sets).
Does that solve all problems? No, it replaces only one of the splits,
usually the inner one!</p>
<p>.smaller[
pro: more stable, more data</p>
<p>con: slower
]</p>
<p>class: center, some-space</p>
</div>
<div class="section" id="cross-validation-test-set">
<h2>Cross-validation + test set<a class="headerlink" href="#cross-validation-test-set" title="Permalink to this headline">¶</a></h2>
<p><img alt=":scale 105%" src="../_images/grid_search_cross_validation_new.png" /></p>
<p>Here is how the workflow looks like when we are using five-fold
cross-validation together with a test-set split for adjusting parameters.
We start out by splitting of the test data, and then we perform
cross-validation on the training set.
Once we found the right setting of the parameters, we retrain on the
whole training set and evaluate on the test set.</p>
</div>
<div class="section" id="grid-search-with-cross-validation">
<h2>Grid-Search with Cross-Validation<a class="headerlink" href="#grid-search-with-cross-validation" title="Permalink to this headline">¶</a></h2>
<p>.smaller[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

<span class="n">cross_val_scores</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">neighbors</span><span class="p">:</span>
    <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">i</span><span class="p">)</span>
    <span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">knn</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
    <span class="n">cross_val_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">))</span>
    
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;best cross-validation score: </span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">cross_val_scores</span><span class="p">)</span><span class="si">:</span><span class="s2">.3</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">best_n_neighbors</span> <span class="o">=</span> <span class="n">neighbors</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">cross_val_scores</span><span class="p">)]</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;best n_neighbors: </span><span class="si">{</span><span class="n">best_n_neighbors</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">best_n_neighbors</span><span class="p">)</span>
<span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test-set score: </span><span class="si">{</span><span class="n">knn</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">best</span> <span class="n">cross</span><span class="o">-</span><span class="n">validation</span> <span class="n">score</span><span class="p">:</span> <span class="mf">0.967</span>
<span class="n">best</span> <span class="n">n_neighbors</span><span class="p">:</span> <span class="mi">9</span>
<span class="n">test</span><span class="o">-</span><span class="nb">set</span> <span class="n">score</span><span class="p">:</span> <span class="mf">0.965</span>
</pre></div>
</div>
<p>]</p>
<p>Here is an implementation of this  for k nearest neighbors.</p>
<p>We split the data, then we iterate over all parameters and for each of
them we do cross-validation.</p>
<p>We had seven different values of n_neighbors, and we are running 10 fold
cross-validation. How many models to we train in total?
10 * 7 + 1 = 71 (the one is the final model)</p>
<p>class: center, middle
<img alt=":scale 80%" src="../_images/gridsearch_workflow.png" /></p>
<p>Here is a conceptual overview of this way of tuning parameters, we start
of with the dataset and a candidate set of parameters we want to try,
labeled parameter grid, for example the number of neighbors.</p>
<p>We split the dataset in to training and test set. We use cross-validation
and the parameter grid to find the best parameters.
We use the best parameters and the training set to build a model with
the best parameters,
and finally evaluate it on the test set.</p>
<p>Because this is such a common pattern, there is a helper class for this
in scikit-learn, called GridSearch CV, which does most of these steps
for you.</p>
</div>
<div class="section" id="gridsearchcv">
<h2>GridSearchCV<a class="headerlink" href="#gridsearchcv" title="Permalink to this headline">¶</a></h2>
<p>.smaller[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>


<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span>  <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">30</span><span class="p">,</span> <span class="mi">2</span><span class="p">)}</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                   <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">grid</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;best mean cross-validation score: </span><span class="si">{</span><span class="n">grid</span><span class="o">.</span><span class="n">best_score_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;best parameters: </span><span class="si">{</span><span class="n">grid</span><span class="o">.</span><span class="n">best_params_</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;test-set score: </span><span class="si">{</span><span class="n">grid</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">best</span> <span class="n">mean</span> <span class="n">cross</span><span class="o">-</span><span class="n">validation</span> <span class="n">score</span><span class="p">:</span> <span class="mf">0.967</span>
<span class="n">best</span> <span class="n">parameters</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="mi">9</span><span class="p">}</span>
<span class="n">test</span><span class="o">-</span><span class="nb">set</span> <span class="n">score</span><span class="p">:</span> <span class="mf">0.993</span>
</pre></div>
</div>
<p>]</p>
<p>Here is an example.
We still need to split our data into training and test set.
We declare the parameters we want to search over as a dictionary. In
this example the parameter is just n_neighbors and the values we want
to try out are a range. The keys of the dictionary are the parameter
names and the values are the parameter settings we want to try. If you
specify multiple parameters, all possible combinations are tried. This
is where the name grid-search comes from - it’s an exhaustive search
over all possible parameter combinations that you specify.</p>
<p>GridSearchCV is a class, and it behaves just like any other model in
scikit-learn, with a fit, predict and score method.
It’s what we call a meta-estimator, since you give it one estimator,
here the KneighborsClassifier, and from that GridSearchCV constructs a
new estimator that does the parameter search for you.
You also specify the parameters you want to search, and the
cross-validation strategy.
Then GridSearchCV does all the other things we talked about, it does the
cross-validation and parameter selection, and retrains a model with the
best parameter settings that were found.
We can check out the best cross-validation score and the best parameter
setting with the best_score_ and best_params_ attributes.
And finally we can compute the accuracy on the test set, simply but
using the score method! That will use the retrained model under the hood.</p>
<p>class: compact</p>
</div>
<div class="section" id="gridsearchcv-results">
<h2>GridSearchCV Results<a class="headerlink" href="#gridsearchcv-results" title="Permalink to this headline">¶</a></h2>
<p>.tiny[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">grid</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">)</span>
<span class="n">results</span><span class="o">.</span><span class="n">columns</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Index</span><span class="p">([</span><span class="s1">&#39;mean_fit_time&#39;</span><span class="p">,</span> <span class="s1">&#39;mean_score_time&#39;</span><span class="p">,</span> <span class="s1">&#39;mean_test_score&#39;</span><span class="p">,</span>
       <span class="s1">&#39;mean_train_score&#39;</span><span class="p">,</span> <span class="s1">&#39;param_n_neighbors&#39;</span><span class="p">,</span> <span class="s1">&#39;params&#39;</span><span class="p">,</span> <span class="s1">&#39;rank_test_score&#39;</span><span class="p">,</span>
       <span class="s1">&#39;split0_test_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split0_train_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split1_test_score&#39;</span><span class="p">,</span>
       <span class="s1">&#39;split1_train_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split2_test_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split2_train_score&#39;</span><span class="p">,</span>
       <span class="s1">&#39;split3_test_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split3_train_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split4_test_score&#39;</span><span class="p">,</span>
       <span class="s1">&#39;split4_train_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split5_test_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split5_train_score&#39;</span><span class="p">,</span>
       <span class="s1">&#39;split6_test_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split6_train_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split7_test_score&#39;</span><span class="p">,</span>
       <span class="s1">&#39;split7_train_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split8_test_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split8_train_score&#39;</span><span class="p">,</span>
       <span class="s1">&#39;split9_test_score&#39;</span><span class="p">,</span> <span class="s1">&#39;split9_train_score&#39;</span><span class="p">,</span> <span class="s1">&#39;std_fit_time&#39;</span><span class="p">,</span>
       <span class="s1">&#39;std_score_time&#39;</span><span class="p">,</span> <span class="s1">&#39;std_test_score&#39;</span><span class="p">,</span> <span class="s1">&#39;std_train_score&#39;</span><span class="p">],</span>
      <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;object&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">0</span>     <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}</span>
<span class="mi">1</span>     <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="mi">3</span><span class="p">}</span>
<span class="mi">2</span>     <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="mi">5</span><span class="p">}</span>
<span class="mi">3</span>     <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="mi">7</span><span class="p">}</span>
<span class="mi">4</span>     <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="mi">9</span><span class="p">}</span>
<span class="mi">5</span>    <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="mi">11</span><span class="p">}</span>
<span class="mi">6</span>    <span class="p">{</span><span class="s1">&#39;n_neighbors&#39;</span><span class="p">:</span> <span class="mi">13</span><span class="p">}</span>
<span class="n">Name</span><span class="p">:</span> <span class="n">params</span><span class="p">,</span> <span class="n">dtype</span><span class="p">:</span> <span class="nb">object</span>
</pre></div>
</div>
<p>]</p>
<p>FIXME text size
GridSearchCV also computes a lot of interesting statistics for you, which
are stored in the cv_results_ attribute. That attribute is a dictionary,
but it’s easiest to convert it to a pandas dataframe to look at it.
Here you can see the columns. Theres mean fit time, mean score time,
mean test scores, mean training scores, standard deviations and scores
for each individual split of the data.
And there is one row for each setting of the parameters we tried out.</p>
<p>class: center</p>
</div>
<div class="section" id="n-neighbors-search-results">
<h2>n_neighbors Search Results<a class="headerlink" href="#n-neighbors-search-results" title="Permalink to this headline">¶</a></h2>
<p><img alt=":scale 70%" src="../_images/grid_search_n_neighbors.png" /></p>
<p>We can use this for example to plot the results of cross-validation over
the different parameters.
Here are the mean training score and mean test score together with one
standard deviation.</p>
<p>class: spacious</p>
</div>
<div class="section" id="nested-cross-validation">
<h2>Nested Cross-Validation<a class="headerlink" href="#nested-cross-validation" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>Replace outer split by CV loop</p></li>
<li><p>Doesn’t yield single model
(inner loop might have different best parameter settings)</p></li>
<li><p>Takes a long time, not that useful in practice</p></li>
</ul>
<p>We could additionally replace the outer split of the data by
cross-validation. That would yield what’s known as nested
cross-validation.
This is sometimes interesting when comparing different models, but it will
not actually yield one final model. It will yield one model for each loop
of the outer fold, which might have different settings of the parameters.
Also, this takes a really long time to train, by an additional factor
of 5 or 10, so this is not used very commonly in practice.</p>
<p>But let’s dive into the cross-validation a bit more.</p>
<p>class: center, middle</p>
</div>
<div class="section" id="cross-validation-strategies">
<h2>Cross-Validation Strategies<a class="headerlink" href="#cross-validation-strategies" title="Permalink to this headline">¶</a></h2>
<p>So I mentioned k-fold cross validation, where k is usually 5 or ten,
but there are many other strategies.</p>
<p>One of the most commonly ones is stratified k-fold cross-validation.</p>
<p>.center[
<img alt=":scale 90%" src="../_images/kfold_cv.png" />
]</p>
<p>class: compact
.center[
<img alt=":scale 90%" src="../_images/stratified_cv.png" />
]
.smallest[
Stratified:
Ensure relative class frequencies in each fold reflect relative class
frequencies on the whole dataset.]</p>
<p>The idea behind stratified k-fold cross-validation is that you want the
test set to be as representative of the dataset as possible.
StratifiedKFold preserves the class frequencies in each fold to be the
same as of the overall dataset.
Here is and example of a dataset with three classes that are ordered. If
you apply standard three-fold to this, the first third of the data would
be in the first fold, the second in the second fold and the third in
the third fold. Because this data is sorted, that would be particularly
bad. If you use stratified cross-validation it would make sure that each
fold has exactly 1/3 of the data from each class.</p>
<p>This is also helpful if your data is very imbalanced. If some of the
classes are very rare, it could otherwise happen that a class is not
present at all in a particular fold.</p>
</div>
<div class="section" id="importance-of-stratification">
<h2>Importance of Stratification<a class="headerlink" href="#importance-of-stratification" title="Permalink to this headline">¶</a></h2>
<p>.smaller[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">y</span><span class="o">.</span><span class="n">value_counts</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="mi">0</span>    <span class="mi">60</span>
<span class="mi">1</span>    <span class="mi">40</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">StratifiedKFold</span>
<span class="kn">from</span> <span class="nn">sklearn.dummy</span> <span class="kn">import</span> <span class="n">DummyClassifier</span>

<span class="n">dc</span> <span class="o">=</span> <span class="n">DummyClassifier</span><span class="p">(</span><span class="s1">&#39;most_frequent&#39;</span><span class="p">)</span>
<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">dc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">skf</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="p">),</span> <span class="n">res</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">dc</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kf</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">res</span><span class="p">),</span> <span class="n">res</span><span class="o">.</span><span class="n">std</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.063</span><span class="p">)</span>
</pre></div>
</div>
<p>]</p>
<p>class: spacious</p>
</div>
<div class="section" id="repeated-kfold-and-leaveoneout">
<h2>Repeated KFold and LeaveOneOut<a class="headerlink" href="#repeated-kfold-and-leaveoneout" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>LeaveOneOut : KFold(n_folds=n_samples)</p></li>
</ul>
<p>High variance, takes a long time</p>
<p>.tiny[(see <a class="reference external" href="https://arxiv.org/pdf/1811.12808.pdf">Raschka</a> for a review and <a class="reference external" href="https://hal.inria.fr/hal-01545002/file/paper.pdf">Varoquaux</a> for empirical evaluation)]</p>
<ul class="simple">
<li><p>Better: ShuffleSplit (aka Monte Carlo)</p></li>
</ul>
<p>Repeatedly sample a test set with replacement</p>
<ul class="simple">
<li><p>Even Better: RepeatedKFold.</p></li>
</ul>
<p>Apply KFold or StratifiedKFold multiple times with shuffled data.</p>
<p>If you want even better estimates of the generalization performance,
you could try to increase the number of folds, with the extreme
of creating one fold per sample. That’s called “LeaveOneOut
cross-validation”. However, because the test-set is so small every time,
and the training sets all have very large overlap, this method has very
high variance.
A better way to get a robust estimate is to run 5-fold or 10-fold
cross-validation multiple times, while shuffling the dataset.</p>
<p>class: compact
.center[
<img alt=":scale 100%" src="../_images/shuffle_split_cv.png" />
]
.smaller[Number of iterations and test set size independent]</p>
<p>Another interesting variant is shuffle split and stratified shuffle
split. In shuffle split, we repeatedly sample disjoint training and test
sets randomly.
You only have to specify the number of iterations, the training set size
and the test set size. This also allows you to run many iterations with
reasonably large test-sets.
It’s also great if you have a very large training set and you want to
subsample it to get quicker results.</p>
<p>class: compact
.center[
<img alt=":scale 100%" src="../_images/repeated_stratified_kfold.png" />
]
.smaller[
Potentially less variance than StratifiedShuffleSplit.</p>
<p>Five times five fold or at most ten times ten fold is sufficient.
]</p>
<p>class: spacious</p>
</div>
<div class="section" id="defaults-in-scikit-learn">
<h2>Defaults in scikit-learn<a class="headerlink" href="#defaults-in-scikit-learn" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p>5-fold in 0.22 (used to be 3 fold)</p></li>
<li><p>For classification cross-validation is stratified</p></li>
<li><p>train_test_split has stratify option:
train_test_split(X, y, stratify=y)</p></li>
<li><p>No shuffle by default!</p></li>
</ul>
<p>By default, all cross-validation strategies are five fold.
If you do cross-validation for classification, it will be stratified
by default.
Because of how the interface is done, that’s not true for
train_test_split and if you want a stratified train_test_split, which
is always a good idea, you should use stratify=y
Another thing that’s important to keep in mind is that by default
scikit-learn doesn’t shuffle! So if you run cross-validation twice
with the default parameters, it will yield exactly the same results.</p>
<p>class: center, middle</p>
</div>
<div class="section" id="cross-validation-with-non-iid-data">
<h2>Cross-Validation with non-iid data<a class="headerlink" href="#cross-validation-with-non-iid-data" title="Permalink to this headline">¶</a></h2>
</div>
<div class="section" id="grouped-data">
<h2>Grouped Data<a class="headerlink" href="#grouped-data" title="Permalink to this headline">¶</a></h2>
<div class="section" id="assume-have-data-medical-product-user-from-5-cities">
<h3>Assume have data (medical, product, user…) from 5 cities<a class="headerlink" href="#assume-have-data-medical-product-user-from-5-cities" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>New York, San Francisco, Los Angeles, Chicago, Houston.</p></li>
</ul>
<p>We can assume data within a city is more correlated then between cities.</p>
</div>
<div class="section" id="usage-scenarios">
<h3>Usage Scenarios<a class="headerlink" href="#usage-scenarios" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Assume all future users will be in one of these cities: i.i.d.</p></li>
<li><p>Assume we want to generalize to predict for a new city: not i.i.d.</p></li>
</ul>
<p>Shipped product in 4 cities. Might ship in another one?
States: you have all the states, no new state will start to exist</p>
<p>Similar thing for multiple measurements per patient.
Or geospacial data.</p>
<p><img alt=":scale 100%" src="../_images/group_kfold.png" /></p>
<p>A somewhat more complicated approach is group k-fold.
This is actually for data that doesn’t fulfill our IID assumption and
has correlations between samples.
The idea is that there are several groups in the data that each contain
highly correlated samples.
You could think about patient data where you have multiple samples for
each patient, then the groups would be which patient a measurement was
taken from.
If you want to know how well your model generalizes to new patients,
you need to ensure that the measurements from each patient are either
all in the training set, or all in the test set.
And that’s what GroupKFold does.
In this example, there are four groups, and we want three folds. The
data is divided such that each group is contained in exactly one fold.
There are several other cross-validation methods in scikit-learn that
use these groups.</p>
<p>class: center</p>
</div>
</div>
<div class="section" id="correlations-in-time-and-or-space">
<h2>Correlations in time (and/or space)<a class="headerlink" href="#correlations-in-time-and-or-space" title="Permalink to this headline">¶</a></h2>
<p><img alt=":scale 70%" src="../_images/time_series1.png" /></p>
<p>Not necessarily obvious that there is a time component!
Data collection usually happens over time!</p>
<p>class: center</p>
</div>
<div class="section" id="id1">
<h2>Correlations in time (and/or space)<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<p><img alt=":scale 70%" src="../_images/time_series2.png" /></p>
<p>Not necessarily obvious that there is a time component!
Data collection usually happens over time!</p>
<p>class: center</p>
</div>
<div class="section" id="id2">
<h2>Correlations in time (and/or space)<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<p><img alt=":scale 70%" src="../_images/time_series3.png" /></p>
<p>Not necessarily obvious that there is a time component!
Data collection usually happens over time!</p>
<p><img alt=":scale 100%" src="../_images/time_series_walk_forward_cv.png" /></p>
<p>Another common case of data that’s not independent is time
series. Usually todays stock price is correlated with yesterdays and
tomorrows. If you randomly split time series, this makes predictions
deceivingly simple. In applications, you usually have data up to some
point, and then try to make predictions for the future, in other words,
you’re trying to make a forecast.
The TimeSeriesSplit in scikit-learn simulates that, by taking increasing
chunks of data from the past and making predictions on the next
chunk. This is quite different from the other was to do cross-validation,
in that the training sets are all overlapping, but it’s more appropriate
for time-series.</p>
<p><img alt=":scale 100%" src="../_images/time_series_cv.png" /></p>
<p>Another common case of data that’s not independent is time
series. Usually todays stock price is correlated with yesterdays and
tomorrows. If you randomly split time series, this makes predictions
deceivingly simple. In applications, you usually have data up to some
point, and then try to make predictions for the future, in other words,
you’re trying to make a forecast.
The TimeSeriesSplit in scikit-learn simulates that, by taking increasing
chunks of data from the past and making predictions on the next
chunk. This is quite different from the other was to do cross-validation,
in that the training sets are all overlapping, but it’s more appropriate
for time-series.</p>
</div>
<div class="section" id="using-cross-validation-generators">
<h2>Using Cross-Validation Generators<a class="headerlink" href="#using-cross-validation-generators" title="Permalink to this headline">¶</a></h2>
<p>.tiny[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">StratifiedKFold</span><span class="p">,</span> <span class="n">ShuffleSplit</span><span class="p">,</span> <span class="n">RepeatedStratifiedKFold</span>
<span class="n">kfold</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">skfold</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ss</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">train_size</span><span class="o">=.</span><span class="mi">4</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=.</span><span class="mi">3</span><span class="p">)</span>
<span class="n">rs</span> <span class="o">=</span> <span class="n">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;KFold:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;StratifiedKFold:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">skfold</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;ShuffleSplit:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">ss</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;RepeatedStratifiedKFold:&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">rs</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
<span class="n">KFold</span><span class="p">:</span>
<span class="p">[</span><span class="mf">0.93</span> <span class="mf">0.96</span> <span class="mf">0.96</span> <span class="mf">0.98</span> <span class="mf">0.96</span><span class="p">]</span>
<span class="n">StratifiedKFold</span><span class="p">:</span>
<span class="p">[</span><span class="mf">0.98</span> <span class="mf">0.96</span> <span class="mf">0.96</span> <span class="mf">0.97</span> <span class="mf">0.96</span><span class="p">]</span>
<span class="n">ShuffleSplit</span><span class="p">:</span>
<span class="p">[</span><span class="mf">0.98</span> <span class="mf">0.96</span> <span class="mf">0.96</span> <span class="mf">0.98</span> <span class="mf">0.94</span> <span class="mf">0.96</span> <span class="mf">0.95</span> <span class="mf">0.98</span> <span class="mf">0.97</span> <span class="mf">0.92</span> <span class="mf">0.94</span> <span class="mf">0.97</span> <span class="mf">0.95</span> <span class="mf">0.92</span>
 <span class="mf">0.98</span> <span class="mf">0.98</span> <span class="mf">0.97</span> <span class="mf">0.94</span> <span class="mf">0.97</span> <span class="mf">0.95</span><span class="p">]</span>
<span class="n">RepeatedStratifiedKFold</span><span class="p">:</span>
<span class="p">[</span><span class="mf">0.99</span> <span class="mf">0.96</span> <span class="mf">0.97</span> <span class="mf">0.97</span> <span class="mf">0.95</span> <span class="mf">0.98</span> <span class="mf">0.97</span> <span class="mf">0.98</span> <span class="mf">0.97</span> <span class="mf">0.96</span> <span class="mf">0.97</span> <span class="mf">0.99</span> <span class="mf">0.94</span> <span class="mf">0.96</span>
 <span class="mf">0.96</span> <span class="mf">0.98</span> <span class="mf">0.97</span> <span class="mf">0.96</span> <span class="mf">0.96</span> <span class="mf">0.97</span> <span class="mf">0.97</span> <span class="mf">0.96</span> <span class="mf">0.96</span> <span class="mf">0.96</span> <span class="mf">0.98</span> <span class="mf">0.96</span> <span class="mf">0.97</span> <span class="mf">0.97</span>
 <span class="mf">0.97</span> <span class="mf">0.96</span> <span class="mf">0.96</span> <span class="mf">0.95</span> <span class="mf">0.96</span> <span class="mf">0.99</span> <span class="mf">0.98</span> <span class="mf">0.93</span> <span class="mf">0.96</span> <span class="mf">0.98</span> <span class="mf">0.98</span> <span class="mf">0.96</span> <span class="mf">0.96</span> <span class="mf">0.95</span>
 <span class="mf">0.97</span> <span class="mf">0.97</span> <span class="mf">0.96</span> <span class="mf">0.97</span> <span class="mf">0.97</span> <span class="mf">0.97</span> <span class="mf">0.96</span> <span class="mf">0.96</span><span class="p">]</span>
</pre></div>
</div>
<p>]</p>
<p>Ok, so how do we use these cross-validation generators? We can simply
pass the object to the cv parameter of the cross_val_score function,
instead of passing a number. Then that generator will be used.
Here are some examples for k-neighbors classifier.
We instantiate a Kfold object with the number of splits equal to 5,
and then pass it to cross_val_score.
We can do the same with StratifiedKFold, and we can also shuffle if we
like, or we can use Shuffle split.</p>
</div>
<div class="section" id="cross-validate-function">
<h2>cross_validate function<a class="headerlink" href="#cross-validate-function" title="Permalink to this headline">¶</a></h2>
<p>.smaller[</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="n">res</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                     <span class="n">scoring</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;roc_auc&quot;</span><span class="p">])</span>
<span class="n">res_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">res</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">fit_time</span>	<span class="n">score_time</span>	<span class="n">test_accuracy</span>	<span class="n">test_roc_auc</span>	<span class="n">train_accuracy</span>	<span class="n">train_roc_auc</span>
<span class="mf">0.000839</span>	<span class="mf">0.010204</span>    <span class="mf">0.965217</span>	    <span class="mf">0.996609</span>	    <span class="mf">0.980176</span>	    <span class="mf">0.997654</span>
<span class="mf">0.000870</span>	<span class="mf">0.014424</span>    <span class="mf">0.956522</span>	    <span class="mf">0.983689</span>	    <span class="mf">0.975771</span>	    <span class="mf">0.998650</span>
<span class="mf">0.000603</span>	<span class="mf">0.009298</span>    <span class="mf">0.982301</span>	    <span class="mf">0.999329</span>	    <span class="mf">0.971491</span>	    <span class="mf">0.996977</span>
<span class="mf">0.000698</span>	<span class="mf">0.006670</span>    <span class="mf">0.955752</span>	    <span class="mf">0.984071</span>	    <span class="mf">0.978070</span>	    <span class="mf">0.997820</span>
<span class="mf">0.000611</span>	<span class="mf">0.006559</span>    <span class="mf">0.964602</span>	    <span class="mf">0.994634</span>	    <span class="mf">0.978070</span>	    <span class="mf">0.998026</span>
</pre></div>
</div>
<p>]</p>
<p>FIXME alignment</p>
<p>class: middle</p>
</div>
<div class="section" id="questions">
<h2>Questions ?<a class="headerlink" href="#questions" title="Permalink to this headline">¶</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="n">sklearn</span><span class="o">.</span><span class="n">set_config</span><span class="p">(</span><span class="n">print_changed_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_digits</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">digits</span> <span class="o">=</span> <span class="n">load_digits</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">digits</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">digits</span><span class="o">.</span><span class="n">target</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span>
                <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">RepeatedStratifiedKFold</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span>
                <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">KNeighborsClassifier</span><span class="p">(),</span>
                <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span>
                <span class="n">cv</span><span class="o">=</span><span class="n">RepeatedStratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="grid-searches">
<h2>Grid Searches<a class="headerlink" href="#grid-searches" title="Permalink to this headline">¶</a></h2>
<p>Grid-Search with build-in cross validation</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
</pre></div>
</div>
</div>
</div>
<p>Define parameter grid:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
              <span class="s1">&#39;gamma&#39;</span> <span class="p">:</span> <span class="mf">10.</span> <span class="o">**</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">0</span><span class="p">)}</span>

<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>A GridSearchCV object behaves just like a normal classifier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_params_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_score_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">grid_search</span><span class="o">.</span><span class="n">best_estimator_</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># We extract just the scores</span>

<span class="n">scores</span> <span class="o">=</span> <span class="n">grid_search</span><span class="o">.</span><span class="n">cv_results_</span><span class="p">[</span><span class="s1">&#39;mean_test_score&#39;</span><span class="p">]</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">matshow</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;gamma&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;C&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">5</span><span class="p">),</span> <span class="n">param_grid</span><span class="p">[</span><span class="s1">&#39;gamma&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">),</span> <span class="n">param_grid</span><span class="p">[</span><span class="s1">&#39;C&#39;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="exercises">
<h2>Exercises<a class="headerlink" href="#exercises" title="Permalink to this headline">¶</a></h2>
<p>Use GridSearchCV to adjust n_neighbors of KNeighborsClassifier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># %load solutions/grid_search_k_neighbors.py</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>


              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="09-pipeline.html" title="previous page">Algorithm Chains and Pipelines</a>
    <a class='right-next' id="next-link" href="../02-supervised-learning/index.html" title="next page">Supervised Learning Algorithms</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Andreas C. Müller<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    <script src="../_static/js/index.js"></script>
    
  </body>
</html>